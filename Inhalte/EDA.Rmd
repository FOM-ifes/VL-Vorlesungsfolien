```{r setup-EDA, include=FALSE}
# ---------------------------------------------------------------------------
#% maintainer:
#%   - Matthias Gehrke
#%
# ---------------------------------------------------------------------------
source("../prelude.R")
initPart(
    "EDA",                # Dateiname ohne Suffix
    "Einfuehrung"         # Verzeichnisname im Bilderverzeichnis 
    )
pathToImages <- getPathToImages()
# ---------------------------------------------------------------------------

library(mosaic)
library(gridExtra)
library(latex2exp)

tips <- assertData("tips.csv", "https://goo.gl/whKjnl")
```

# Explorative Datenanalyse 

### Lernziele {exclude=NOlernziele, include-only=MasterNeu}

Die Studierenden ...

- können Gründe für den Einsatz von R nennen.
- können die Unterschiede zwischen R, RStudio und mosaic erläutern.
- können R in Grundzügen anwenden (wie Datensätze laden und einfache Befehle eingeben).
- können den Aufbau des CSV-Formats erklären und CSV-Daten in RStudio importieren.
- kennen zentrale Statistiken und Visualisierungen für nominal skalierte Variablen und können diese anwenden.
- kennen zentrale Statistiken und Visualisierungen für numerisch skalierte Variablen und können diese anwenden.
- kennen zentrale Statistiken und Visualisierungen zum Zusammenhang zweier metrischer Variablen und können diese anwenden.


### Lernziele {exclude=NOlernziele,MasterNeu}

Die Studierenden ...

- können den Aufbau des CSV-Formats erklären und CSV-Daten in RStudio importieren.
- kennen zentrale Statistiken und Visualisierungen für nominal skalierte Variablen und können diese anwenden.
- kennen zentrale Statistiken und Visualisierungen für numerisch skalierte Variablen und können diese anwenden.
- kennen zentrale Statistiken und Visualisierungen zum Zusammenhang zweier metrischer Variablen und können diese anwenden.


## Einführung in R {include-only=MasterNeu}


### Cartoon: Computereinsatz in der Statistik {include-only=MasterNeu}

```{r echo=FALSE, out.width = "50%", fig.align="center", cache=FALSE}
# Lizenzworkaround: 
extern_image_include("https://www.causeweb.org/cause/sites/default/files/caption_contest/2018/Caption-Contest_05-2018.jpg", "cartoon0518.jpg", pathToImages)
```
"Auch wenn die Zeit für das 'Einsetzen von Zahlen in Formeln' und das 'Abbildungen zeichnen per Hand` gekommen ist: die Ideen und Konzepte leben weiter -- in unseren Computerprogrammen."^[[https://www.CAUSEweb.org/](https://www.causeweb.org/cause/caption-contest/may/2018/results) &copy; J.B. Landers, Bildunterschrift K. Lübke]


### Warum R? {include-only=MasterNeu}

> [...] she was also following a wider trend: for many academics [...] R is the data-analysis tool of choice.^[Tippmann, S.. Programming tools (2015): Adventures with R. A guide to the popular, free statistics and visualization software that gives scientists control of their own data analysis. Nature, 517, S. 109--110. [https://doi.org/10.1038%2F517109a](https://doi.org/10.1038%2F517109a)]

Verbreitung z.B.: [http://r4stats.com/articles/popularity/](http://r4stats.com/articles/popularity/)

**R ist eine weit verbreitete Eintrittskarte in das globale Datenzeitalter!**


### Vorteile R {include-only=MasterNeu}

- Methoden- und Anwendungsvielfalt (Finance, Marketing, HR, Psychologie, ...)^[Siehe z.B. [https://cran.r-project.org/web/views/](https://cran.r-project.org/web/views/)]

- Neue Methoden der Datenanalyse werden häufig in R entwickelt (auch Big Data, KI,  etc. ).

- frei und offen; kostenlos

- Schnittstellen zu sehr vielen Datenquellen/ -banken (auch SocialMedia etc.)

- Erweiterungen u.a. für Microsoft, Oracle, SAP-Produkte, aber auch SPSS, SAS

- unzählige Nutzer*innen weltweit in Unternehmen und Wissenschaft

- Möglichkeiten für Reporting, Apps, etc.

- numerische Stabilität/ Genauigkeit

- große Entwickler*innen-Gemeinde mit langer Geschichte (seit 1993); R Konsortium, u.a. IBM, Microsoft, TIPCO, Google, ...


### Übung `r nextExercise()`: R in der Wissenschaft {.exercise type=A-B answer=B include-only=MasterNeu}

Welchen Vorteil hat R in Bezug auf die Gütekriterien für Forschung?

A.  kostenlos
B.  offen

::: {.notes}
Transparenz ist eines der Gütekriterien für Forschung, und die wird durch Offenheit ermöglicht, also ***B***.
:::




### Statistik, R, Rstudio und mosaic {include-only=MasterNeu}

- *Statistik*  ist das *Auto*, mit dem der Weg von der Forschungsfrage zur vorläufigen Antwort bestritten werden kann.

- *R* ist ein *Motor*, der das Auto antreiben kann.

- *RStudio Desktop* ist das Cockpit, mit dem der Motor gesteuert werden kann.

- *mosaic* ist eine *Zusatzausstattung*, um die Motorsteuerung zu vereinfachen.


### R und Co. {include-only=MasterNeu}

- **R** [https://www.r-project.org/](https://www.r-project.org/): ist das Basisprogramm

- **RStudio Desktop** [https://posit.co/downloads/](https://posit.co/downloads/): ist eine komfortable Entwicklungsumgebung für R und bietet zusätzliche Tools, wie z.B. Dokumentenerstellung etc.

Ausführliche Installationsanleitung [hier](https://fomshinyapps.shinyapps.io/Installation-R-RStudio-mosaic/).

Alternative zur Installation von R: Clouddienst [https://posit.cloud/plans/free](https://posit.cloud/plans/free)


### Installation Zusatzpakete {include-only=MasterNeu}

- **mosaic** [https://cran.r-project.org/web/packages/mosaic/](https://cran.r-project.org/web/packages/mosaic/): ist ein Zusatzpaket, welches u.a. eine vereinheitlichte R Syntax bietet


**Installation:**

Pakete werden **einmalig** über `install.packages()` **installiert**, im Falle von mosaic: 
```{r, eval=FALSE}
install.packages("mosaic")
```

Bei **jeder** neuen Sitzung müssen sie erneut geladen werden.^[[https://twitter.com/visnut/status/1248087845589274624](https://twitter.com/visnut/status/1248087845589274624)]


<!-- ```{r echo=FALSE, out.width = "60%", fig.align="center", cache=FALSE, fig.cap="Quelle: Dianne Cook - https://twitter.com/visnut/status/1248087845589274624"} -->
<!-- knitr::include_graphics("images/Einfuehrung/install-use-R-packages.jpg", error=FALSE) -->
<!-- ``` -->

### Vorteile Code {include-only=MasterNeu} 

- Dokumentation des Vorgehens
- (Einfache) Nachvollziehbarkeit, Wiederholung
- Möglichkeit zur Automatisierung und Übertragung
- "Direkte" Kommunikation mit dem Programm/ Computer
- Speziell R: unzählige Literatur und Hilfe/ Tutorials im Internet


### Code: mosaic {include-only=MasterNeu}

```{r, eval = FALSE}
analysiere( y  # ggfs. abhängige Variable
            ~  x # unabhängige Variable(n)
            | z, # ggfs. bedingende (gruppierende) Variable(n)
            Optionen, # ggfs. weitere Optionen
            data = meine_daten ) # Datentabelle 
```

`analysiere()`: Was soll R tun?^[Befehlsübersicht [hier](https://www.fom.de/fileadmin/fom/forschung/ifes/Cheatsheet-DA-R.pdf); Tilde `~` unter macOS: `alt+n`, vertikaler Strich `|`: `alt+7`]



Zentrale Fragen:

1. Was soll der Computer für mich tun?
2. Was muss der Computer dafür wissen?


### Kochen mit RStudio^[Idee und in Anlehnung an [Jessica Ward.](https://twitter.com/RLadiesNCL/status/1138812826917724160)] {include-only=MasterNeu}
```{r echo=FALSE, out.width = "100%", fig.align="center", cache=FALSE}
knitr::include_graphics("images/Einfuehrung/Kochen_mit_RStudio.png", error=FALSE)
```


### `mosaic` nutzen {include-only=MasterNeu}

Paket `mosaic` in jeder Sitzung laden:

```{r, message=TRUE}
library(mosaic)
```

<!-- **************************************************** -->
<!-- TODO: Gelegentlich überprüfen und ggf. aktualisieren -->
<!-- **************************************************** -->

Die dabei angezeigten folgenden Meldungen^[`mosaic` Version 1.8] sind nur Hinweise, [keine]{.cemph} Fehler:


:::{.tiny}

```
The 'mosaic' package masks several functions from core packages in order to add 
additional features.  The original behavior of these functions should not be affected by this.

Attache Paket: ‘mosaic’

The following objects are masked from ‘package:dplyr’:

[...]


The following objects are masked from ‘package:base’:

    max, mean, min, prod, range, sample, sum

```

:::


### Sebastians Kaffeemühle {include-only=sesmill}

```{r echo=FALSE, out.width = "20%", fig.align="right"}
knitr::include_graphics(file.path(pathToImages, "maschine.jpg"), error = FALSE)
```

- Um den Kaffee zu beschreiben, braucht man in der Regel Abbildungen und Zahlen.
- Die Bohnen (Daten) werden zu Kaffee (Visualisierungen und Kennzahlen) gemahlen.^[Skizze: Sebastian Sauer]

<!-- -->


## Daten einlesen

### Trinkgeld-Datentabelle

Einlesen der *Tipping*^[Bryant, P. G. and Smith, M (1995) Practical Data Analysis: Case Studies in Business Statistics. Homewood, IL: Richard D. Irwin Publishing] -Daten:^[Falls Sie aktuell noch kein lauffähiges R haben: [https://fomshinyapps.shinyapps.io/micRo-tips/](https://fomshinyapps.shinyapps.io/micRo-tips/)]
```{r, message = FALSE, eval = FALSE}
# Herunterladen 
download.file("https://goo.gl/whKjnl", destfile = "tips.csv")
# Einlesen in R
tips <- read.csv2("tips.csv")

# Alternativ - heruntergeladene Datei einlesen
#   und das Verzeichnis auswählen:
# tips <- read.csv2(file.choose()) 
```

[*Tipp*:]{.cemph} Über den Befehl `getwd()` wird das aktuelle Verzeichnis
ausgegeben.


### `csv`-Datei

Dateiaufbau `tips.csv`^[Eine solche `csv`-Datei kann z.B. durch Export aus Tabellenkalkulationsprogrammen erzeugt werden.]:

- [Erste Zeile:]{.cemph} Variablennamen^[Tipp: Mit Buchstaben beginnen, keine Leer- oder Sonderzeichen, Umlaute vermeiden.]
- [Datenfeldtrennzeichen der Variablen:]{.cemph} `;` (Semikolon)^[In amerikanischen csv-Dateien ist das Datenfeldtrennzeichen das Komma (daher der Name: `csv` -- *Comma Separated Values*) und das Dezimaltrennzeichen der Punkt. Diese werden mit `read.csv()` eingelesen.]
- [Dezimaltrennzeichen:]{.cemph} `,` (Komma)
- [Textkennzeichen:]{.cemph} `"` (Anführungszeichen)

:::{.scriptsize}

```
"total_bill";"tip";"sex";"smoker";"day";"time";"size"
16,99;1,01;"Female";"No";"Sun";"Dinner";2
10,34;1,66;"Male";"No";"Sun";"Dinner";3
21,01;3,5;"Male";"No";"Sun";"Dinner";3
23,68;3,31;"Male";"No";"Sun";"Dinner";2
...
```
:::


[*Hinweis*:]{.cemph} Der Einlesebefehl in R hängt vom Dateiformat der Datei ab.
Siehe z.B. `?read.table` oder die Pakete 
[readr](https://cran.r-project.org/package=readr) und 
[readxl](http://readxl.tidyverse.org).


### Variablen Trinkgeld-Datentabelle {exclude=MasterNeu}

Ein Kellner sammelte über mehrere Monate Daten über sein Trinkgeld:

- `total_bill`: Rechnungshöhe in Dollar
- `tip`: Trinkgeld in Dollar
- `sex`: Geschlecht des Rechnungszahlenden
- `smoker`: Gab es Raucher\*innen am Tisch?
- `day`: Wochentag 
- `time`: Tageszeit/ Mahlzeit
- `size`: Anzahl Personen am Tisch


`str()` gibt Informationen zur Struktur der Datentabelle:

```{r str-tips, eval=FALSE}
str(tips)
```
::: {.scriptsize}

```{r ref.label="str-tips", echo=FALSE}
```

:::


### Variablen Trinkgeld-Datentabelle {include-only=MasterNeu}

Ein Kellner sammelte über mehrere Monate Daten über sein Trinkgeld:

- `total_bill`: Rechnungshöhe in Dollar
- `tip`: Trinkgeld in Dollar
- `sex`: Geschlecht des Rechnungszahlenden
- `smoker`: Gab es Raucher\*innen am Tisch?
- `day`: Wochentag 
- `time`: Tageszeit/ Mahlzeit
- `size`: Anzahl Personen am Tisch


### Variablentypen in R {include-only=MasterNeu}

`str()` gibt Informationen zur Struktur der Datentabelle:

```{r str2-tips, eval=FALSE}
str(tips)
```
::: {.scriptsize}

```{r str2-tips, echo=FALSE}
```
:::

Eine Datentabelle (`data.frame`) kann aus mehreren Variablen (Spalten) mit gleicher Anzahl Beobachtungen (Zeilen) bestehen. Für Variablen gibt es verschiedene Typen, u.a.:

- Zeichenketten (`character`) und Faktoren (`factor`)^[Faktoren sind Zeichenketten, die eine definierte Menge an Werten (Ausprägungen, `levels`) annehmen können.].
- Gleitkommazahlen (`numeric` bzw. `double`) und ganze Zahlen (`integer`).

<!-- -->

### mosaic {exclude=MasterNeu}

```{r mosaic, message=FALSE}
# Ggfs. einmalig vorab installieren
# install.packages("mosaic")

# Pakete müssen bei jedem Start von R bzw. RStudio geladen werden
# Paket mosaic laden
library(mosaic)

```

<!-- -->

### Übung `r nextExercise()`: Aufbau Datentabelle {.exercise type=A-B-C-D-E answer=C}

Wie viele kategoriale Variablen liegen vor?

A.  1
B.  2
C.  4
D.  7
E.  244

::: {.notes}
Es liegen ***4 (Antwort C)*** kategoriale Variablen vor 
(`sex`, `smoker`, `day`, `time`), als `Factor` gespeichert. 
Die anderen sind metrische Variablen, 1 davon diskret (`size` -- `integer`),
2 stetig (`total_bill`, `tip` -- `numeric`). 
7 ist die Gesamtzahl an Variablen und 244 ist die Anzahl der Beobachtungen.
:::


### Übung `r nextExercise()`: Datenerhebung {.exercise type=A-B answer=A exclude=qmwinf,eufom}

Was vermuten Sie: Um welche Form der Datenerhebung handelt es sich hier?

A.  Beobachtungsstudie.
B.  Experiment.

Was folgt daraus?

::: {.notes}
Vermutlich liegt eine Beobachtungsstudie (***A***) vor -- Sekundärerhebung: 
Nutzung vorhandener Daten. D.h., es können keine unmittelbaren Kausalaussagen 
getroffen werden. 
Bei einer zufälligen Stichprobe kann auf die Population geschlossen werden.
:::

<!-- -->

## Analyse kategorialer Daten

### Übersicht

**Grafiken**

- *Säulendiagramm / Balkendiagramm*: Häufigkeit von Merkmalsausprägungen (nominal, ordinal, metrisch diskret).
  - vertikale Ausrichtung: Säulendiagramm
  - horizontale Ausrichtung: Balkendiagramm
- *Mosaikplot*: Darstellung der Merkmalsausprägungen zweier nominaler Merkmale.
- ~~*Kreisdiagramm*~~^[siehe z.B. Regel 20 von [https://robjhyndman.com/hyndsight/graphics/](https://robjhyndman.com/hyndsight/graphics/)]

**Häufigkeiten**

- *Anteile*: Relative Anzahl der verschiedenen Merkmalsausprägungen kategorialer Merkmale (nominal, ordinal).
- *Kreuztabelle*: Tabelle der verschiedenen Merkmalsausprägungen kategorialer Merkmale (nominal, ordinal), entweder in absoluten oder relativen Häufigkeiten.


### Säulendiagramm

Visualisiert die absoluten oder relativen Häufigkeiten von Beobachtungen von 
kategorialen (oder metrisch diskreten) Variablen durch die Höhe der Säulen.

```{r echo = FALSE, out.width = "70%", fig.asp = 0.5, fig.align = "center"}
plot1 <- gf_bar(~ sex, data = tips, xlab = "Kategoriale Variable: sex") %>%   # kategoriale Variable
  gf_theme(axis.title.x = element_text(size = 20))
plot2 <- gf_bar(~ size, data = tips, xlab = "Metrisch diskrete Variable: size") %>%  # metrisch diskrete Variable
    gf_theme(axis.title.x = element_text(size = 20))
# Gebe die Plots nebeneinander aus
grid.arrange(plot1, plot2, nrow = 1)
```


### Analyse: Geschlecht Rechnungszahler*in

Analysiere über Säulendiagramm:

```{r EDA_bargraph, fig.align="center", out.width="50%"}
gf_bar( ~ sex, # (unabhängige) Variable, die analysiert wird
          data = tips) # Datentabelle
```


### Übung `r nextExercise()`: Geschlechtsverteilung {.exercise type=A-B-C answer=B}

```{r EDA_bargraph, echo=FALSE, fig.align="right", out.width="20%"}
```


Welche Aussage stimmt?

A.  Bei einer Mehrheit der Stichprobe zahlt eine Frau.
B.  Bei einer Mehrheit der Stichprobe zahlt ein Mann.
C.  Weiß nicht.

::: {.notes}
***B*** ist korrekt, da die Säule für `Male` höher als die für `Female` ist. 
:::


### Anteil der Frauen unter den Rechnungszahler*innen

Analysiere über Anteil $p$:

```{r}
prop( ~ sex,  # (unabhängige) Variable, die analysiert wird
      data = tips) # Datentabelle
```

[*Hinweis*:]{.cemph} Über die zusätzliche *Option* `success` kann festgelegt 
werden, wovon der Anteil bestimmt werden soll.

```{r}
prop( ~ sex,  # (unabhängige) Variable, die analysiert wird
      success = "Female", # wovon den Anteil bestimmen
      data = tips) # Datentabelle
```


### Tabellierung

Analysiere über Tabellen:

Absolute Häufigkeit $h_i$:

```{r tally-beispiel1}
tally( ~ sex, # Variable, die analysiert wird
       data = tips) # Datentabelle
```

Relative Häufigkeit $f_i=\frac{h_i}{n}$ (Option `format = "proportion"`):

```{r tally-beispiel2}
tally( ~ sex, # Variable, die analysiert wird
       format = "proportion", # Option: Anteile
       data = tips) # Datentabelle
```


### Offene Übung `r nextExercise()`:  Modellierung Geschlecht {.exercise type=essay}

Das Geschlecht des Rechnungszahlenden (`sex`) *variiert*: 
Mal zahlt ein Mann, mal zahlt eine Frau.

Welche der anderen Variablen könnte einen Teil dieser Variation *modellieren*, 
d.h., womit könnte dies zusammenhängen?

::: {.notes}

Hier ist vieles möglich -- im folgenden versuchen wir es mit der Tageszeit 
`time`: Geschlecht des Rechnungszahlenden je Tageszeit.

:::


### Gruppiertes Säulendiagramm

```{r EDA_bargraph-group, fig.align="center", out.width="60%"}
gf_bar( ~ sex # Variable, die analysiert wird
        | time,  # Variable, nach der bedingt wird
        data = tips) # Datentabelle
```


### Übung `r nextExercise()`: Geschlecht nach Tageszeit {.exercise type=A-B-C answer=A}

```{r EDA_bargraph-group, echo=FALSE, fig.align="right", out.width="20%"}
```

Welche Aussage stimmt?

A.  Beim Lunch zahlen mehr Frauen als Männer.
B.  Beim Lunch zahlen weniger Frauen als Männer.
C.  Beim Lunch zahlen gleich viele Frauen wie Männer.

::: {.notes}
Antwort ***A*** ist korrekt, im Bereich `Lunch` ist die Säule für `Female` etwas höher als die für `Male`. Aber man sieht auch, dass der Unterschied klein ist. In der nachfolgenden Kreuztabellierung sehen Sie dies auch in absoluten Zahlen und Anteilen ausgedrückt.
:::


### Kreuztabellierung Geschlecht nach Tageszeit 

::: {.small}

Absolute Häufigkeit je Mahlzeit:

```{r tally_group, echo=TRUE}
tally( ~ sex # Variable, die analysiert wird
       | time,  # Variable, nach der bedingt wird
       data = tips) # Datentabelle

```

Relative Häufigkeit je Mahlzeit:

```{r, echo=TRUE}
tally( ~ sex # Variable, die analysiert wird
       | time,  # Variable, nach der bedingt wird
       format = "proportion", # Option: Anteile
       data = tips) # Datentabelle
```
:::


### Übung `r nextExercise()`: Raucher je Wochentag {.exercise type=A-B answer=A}

Welcher Befehl führt eine Kreuztabellierung der Anteile der Raucher je Wochentag durch?

A.  `tally( ~ smoker | day, format = 'proportion', data = tips)`
B.  `tally( ~ day | smoker, format = 'proportion', data = tips)`

:::{.footnotesize}
[*Hinweis*:]{.cemph} Alternativer Code:

- `tally(smoker ~ day, format = 'proportion', data = tips)` 
- `tally(day ~ smoker, format = 'proportion', data = tips)`
:::


::: {.notes}
***A*** ist die korrekte Antwort.  
In dieser Reihenfolge werden zeilenweise die Ausprägungen von `smoker` dargestellt
und spaltenweise die Ausprägungen von `day`, grundsätzliche Formeleingabe `y ~ x | z`, hier `smoker` gruppiert nach `day`. Mit `format = ‘proportion’` werden die Anteile der Ausprägungen bezogen auf die jeweilige Spalte berechnet. 
:::


### Kreuztabellierung Raucher und Wochentag

```{r}
tally( ~ smoker | day, format = "proportion", data = tips)

tally( ~ day | smoker, format = "proportion", data = tips)
```


### Relative Häufigkeiten

[**Achtung**]{.cstrong} [(Confusion of the inverse)]{.cemph}[**:**]{.cstrong} Wovon wird die relative Häufigkeit angegeben? 

- Der Anteil der Raucher am Freitag entspricht nicht dem Anteil des Freitags der Raucher.

- Der Papst ist ein Mann, aber nur die allerwenigsten Männer sind Papst.^[Auch wenn es zwei Päpste geben würde, hätte sich zwar die relative Häufigkeit der Männer, die Papst sind, verdoppelt, wäre absolut aber immer noch sehr klein.]

- Die Wahrscheinlichkeit, *krank* zu sein, wenn das *Testergebnis positiv* ist, ist nicht dasselbe wie die Wahrscheinlichkeit, dass das *Testergebnis positiv* ist, wenn man *krank* ist. 


### Übung `r nextExercise()`: Fehler {.exercise type=A-B-C-D answer=C exclude=qmwinf,eufom}

Was ist an diesem Befehl falsch?
```{r, eval=FALSE, cache=FALSE}
tally( ~ x data = daten)
```

A.  Es fehlt eine Option.
B.  Es fehlt eine bedingende Variable.
C.  Es fehlt ein Komma.
D.  Gar nichts.

::: {.notes}
Antwort ***C*** ist korrekt, es fehlt ein Komma. Korrekt muss es heißen: `tally( ~ x, data = daten)`.
:::

<!-- -->


### Offene Übung `r nextExercise()`: R Fehler {.exercise type=essay exclude=qmwinf,eufom}

Was ist an diesem Befehl falsch?

```{r, eval=FALSE, cache=FALSE}
Tally( ~ x, data = daten)
```

::: {.notes}
R unterscheidet zwischen Groß- und Kleinschreibung, `Tally` gibt es nicht. 
Korrekt muss es heißen: `tally( ~ x, data = daten)`.
:::

<!-- -->


### Mosaikplot

Visualisiert die gemeinsame Verteilung von zwei kategorialen Variablen. 
Dabei entspricht die Höhe und Breite der Rechtecke der jeweiligen relativen Häufigkeit.

```{r EDA_Titanic, echo=FALSE, out.width = "65%", fig.align="center", cache=FALSE}
data("Titanic")
mosaicplot(~ Class + Survived,  
           color = pal_npg(alpha = 0.8)(2), 
           main = "Überleben auf der Titanic", 
           cex = 1.5,
           data = Titanic)
```


### Übung `r nextExercise()`: Mosaikplot {.exercise type=yesno answer=yes}

```{r EDA_Titanic, echo=FALSE, fig.align="right", out.width="20%", cache=FALSE}
```

Stimmt die Aussage: Der Anteil der Überlebenden ist in der 1. Klasse größer als in den unteren Klassen?

- Ja.
- Nein.

::: {.notes}
***Ja***, da der Flächenanteil für `Yes` relativ größer ist als in den anderen Klassen.
:::


### Mosaikplot Raucher und Tage

So können Sie einen solchen Plot erzeugen.^[Hinweis: Bei `mosaicplot()` sollten in der Formel die Achsen vertauscht werden, also `x ~ y`.]

```{r eval=FALSE, echo=TRUE,fig.align='center', out.width="60%"}
mosaicplot(day ~ smoker, data = tips)
```
```{r evaL=TRUE, echo=FALSE,fig.align='center', out.width="60%"}
mosaicplot(day ~ smoker, data = tips, color = pal_npg(alpha = 0.8)(2), cex = 1.5)
```


## Analyse numerischer (metrischer) Daten

### Übersicht

**Grafiken**

- *Säulendiagramm / Balkendiagramm*: Häufigkeiten von Merkmalsausprägungen (nominal, ordinal, metrisch diskret).
- *Histogramm*: Häufigkeit von gruppierten Merkmalsausprägungen (metrisch).
- *Boxplot*: Visualisierung von Median, oberem und unterem Quartil^[Lagemaße: Erläuterung folgt.], Minimum und Maximum, Ausreißern (metrisch).
- *Streudiagramm/ Scatterplot*: Darstellung der Merkmalsausprägungen von zwei i.d.R. metrischen Merkmalen^[bei kategorialen oder metrisch diskreten Merkmalen ggfs. *verwackeln (engl.: jitter)*] als Punkte.
- *Liniendiagramm*: Verlauf der Merkmalsausprägung eines Merkmals.

**Kennzahlen**

- *Lagemaß*: beschreibt u.a. die zentrale Tendenz einer Verteilung.
- *Streuungsmaß*: beschreibt die Verteilung der Daten (häufig um das Lagemaß).
- *Schiefe*: beschreibt die Form der Verteilung.

<!-- -->
 
 
### Dotplot (I / II) {include-only=deprecated exclude=qmwinf,eufom}

Zeigt die Häufigkeiten der einzelnen Ausprägungen an.

```{r out.width="20%", fig.asp=2}
gf_dotplot( ~ size, data = tips)
```

:::{.footnotesize}
Hinweis: Die Skalierung an der y-Achse ist nicht sinnvoll. 
Sie können sie verbergen mit `gf_dotplot( ~ size, data = tips) %>% gf_theme(scale_y_continuous(NULL, breaks = NULL))`.
:::

<!-- -->


### Dotplot (II / II) {include-only=deprecated exclude=qmwinf,eufom}

Der Dotplot kann auch für stetige Merkmale genutzt werden. 
Dann werden Bereiche in Intervalle (Klassen) zusammengefasst. 
Die Breite können Sie mit `binwidth =` festlegen.

```{r out.width="30%", fig.asp=1.5}
gf_dotplot( ~ total_bill, data = tips, binwidth = 2) %>% 
  gf_theme(scale_y_continuous(NULL, breaks = NULL))
```

<!-- -->


### Histogramm


[Exploring Histograms](http://tinlizzie.org/histograms/): 
Ein **Histogramm** visualisiert die gruppierte Verteilung einer numerischen 
Variable. 
Der Flächeninhalt der Rechtecke entspricht dabei der relativen Häufigkeiten der 
Beobachtungen im Intervall (Klasse). 

```{r EDA_hist, out.width = "50%", fig.align = "center"}
gf_histogram( ~ total_bill, data = tips, binwidth = 10, center = 5)
```


### Übung `r nextExercise()`: Histogramm {.exercise type=A-B-C-D-E-F answer=B}

```{r EDA_hist, echo=FALSE, fig.align="right", out.width="20%"}
```

Welche Aussage stimmt?

A.  Die meisten beobachteten Werte sind $\leq 10$.
B.  Die meisten beobachteten Werte sind $>10$ und $\leq 20$.
C.  Die meisten beobachteten Werte sind $>20$ und $\leq 30$.
D.  Die meisten beobachteten Werte sind $>30$ und $\leq 40$.
E.  Die meisten beobachteten Werte sind $>40$ und $\leq 50$.
F.  Die meisten beobachteten Werte sind $>50$.

::: {.notes}
Antwort ***B*** ist korrekt, da die Säule am höchsten ist -- bei gleicher Säulenbreite -- und somit in dieser Klasse prozentual am meisten Beobachtungen sind.
:::

<!-- -->


### Histogramm: Anzahl der Rechtecke festlegen mit Option `bins =` {include-only=deprecated exclude=qmwinf,eufom}

```{r histogrambins, fig.align="center", out.width="80%", echo=FALSE}
gh2  <- gf_histogram(~ total_bill, data = tips, bins = 2, title ="bins = 2")
gh10 <- gf_histogram(~ total_bill, data = tips, bins = 10, title ="bins = 10")
gh25 <- gf_histogram(~ total_bill, data = tips, bins = 25, title ="bins = 25")
gh50 <- gf_histogram(~ total_bill, data = tips, bins = 50, title ="bins = 50")
grid.arrange(gh2, gh10, gh25, gh50)
```

<!-- -->


### Analyse Rechnungshöhe

Analysiere über Histogramm:

```{r histogram, fig.align="center", out.width="60%"}
gf_histogram( ~ total_bill, # Variable, die analysiert wird
              binwidth = 5, # Breite einer Säule entspricht 5$ 
              data = tips)  # Datentabelle
```


### Übung `r nextExercise()`: Wahl der Visualisierung {.exercise type=A-B-C answer=B}

Mit welchem Verfahren kann die Verteilung des Merkmals Stundenlohn sinnvoll visualisiert werden?

A.  Säulendiagramm.
B.  Histogramm.
C.  Streudiagramm.

::: {.notes}
Es wird *ein* Merkmal analysiert, daher scheidet Streudiagramm aus. 
Stundenlohn ist ein metrisches, quasi-stetiges Merkmal, daher ist ein 
***Histogramm (B)*** eine geeignete Grafik. 
Ein Säulendiagramm wird eher bei diskreten Merkmalen verwendet.

Während das Säulendiagramm zeigen würde, wie häufig jedes einzelne Einkommen 
auftritt, also wie oft z.B. $13{,}10\,\oureuro, 13{,}11\,\oureuro$ usw., 
würde im Histogramm gezeigt, wie oft der Stundenlohn z.B. 
zwischen $13\,\oureuro$ und $14\,\oureuro$ liegt.
:::


### Verteilungen

Die Verteilung gibt an, wie häufig bzw. wahrscheinlich bestimmte Werte oder 
Wertebereiche sind.

Für numerische Variablen:

- Schiefe: Bei **rechtsschiefen** (linkssteilen) Verteilungen sind mehr 
  Beobachtungen im unteren Wertebereich, bei **linksschiefen** (rechtssteilen) 
  im oberen. 

- Bei **symmetrischen** Verteilungen verteilen sich die Daten symmetrisch um 
  eine zentrale Lage (unimodal).

- Bei **mehrgipfligen** Verteilungen gibt es mehr als nur ein Zentrum, um das 
  die Werte streuen.


### Verteilungsformen

```{r, fig.align="center", out.width="90%", echo=FALSE}
source("Fleishman.R")

n <- 10000

xn <- rnorm(n = n)
nor <- data.frame(Verteilung = "Symmetrisch (Normal)", x = xn)

xls <- rfleish(n = n, skew = -0.65)
xrs <- rfleish(n = n, skew = 0.65)
st <- c(rep("Linksschief", n), rep("Rechtsschief", n))
x <- c(xls, xrs)
schiefe <- data.frame(Verteilung = st, x = x)

xl <- rnorm(0.65*n, mean = -1,sd = 0.5)
xr <- rnorm(0.35*n, mean = 1, sd = 0.5)
xmm <- c(xl,xr)
xmm <- (xmm - mean(xmm))/sd(xmm)
bimod <- data.frame(Verteilung = "Bimodal", x = xmm)

x1 <- rnorm(0.35*n, mean = -1,sd = 0.5)
x2 <- rnorm(0.25*n, mean = 3, sd = 1)
x3 <- rnorm(0.40*n, mean = -5, sd = 0.5)
xmm <- c(x1,x2,x3)
xmm <- (xmm - mean(xmm))/sd(xmm)
multimod <- data.frame(Verteilung = "Multimodal", x = xmm)

xg <- runif(n)
xg <- (xg - mean(xg))/sd(xg)
gleich <- data.frame(Verteilung = "Gleichverteilung", x = xg)

dat <- rbind(nor, schiefe,  bimod, multimod, gleich)

gf_histogram(~x | Verteilung, data = dat) %>% 
  gf_theme(axis.text = element_blank(), 
           axis.text.y = element_blank(), 
           axis.title.x = element_blank(), 
           axis.title.y = element_blank(), 
           axis.ticks = element_blank())
```


### Übung `r nextExercise()`: Verteilungsform {.exercise type=A-B-C-D-E answer=E}

Welche Aussage stimmt vermutlich für die Verteilung des Einkommens?

A.  Das Einkommen ist gleichverteilt.
B.  Das Einkommen ist multimodal.
C.  Das Einkommen ist normalverteilt.
D.  Das Einkommen ist linksschief.
E.  Das Einkommen ist rechtsschief.

::: {.notes}
Da, grob gesagt, nur wenige viel und sehr viel verdienen, viele ein mittleres 
Einkommen haben und etwas weniger ein geringes, wird die Verteilung 
rechtsschief sein. 
Antwort ***E*** ist also korrekt. 
*Tipp:* Recherchieren Sie doch mal die Einkommensverteilung in Deutschland.
:::

<!-- --->


### Übung `r nextExercise()`: Rechnungshöhe {.exercise type=A-B-C-D answer=B}

Was gilt für die Variable Rechnungshöhe `total_bill`?

A.  Es ist eine latente verhältnisskalierte Variable.
B.  Es ist eine manifeste verhältnisskalierte Variable.
C.  Es ist eine latente intervallskalierte Variable.
D.  Es ist eine manifeste intervallskalierte Variable.


::: {.notes}
Die Rechnungshöhe lässt sich direkt messen, also ist sie manifest. 
Da es einen absoluten Nullpunkt gibt ist sie verhältnisskaliert, 
also stimmt ***B***.
:::

<!-- --->


### Übung `r nextExercise()`: Rechnungshöhe {.exercise type=A-B-C-D-E answer=E}

```{r histogram, echo=FALSE, fig.align="right", out.width="20%"}
```

Welche der folgenden Aussagen stimmt?

A.  Die Rechnungshöhe ist gleichverteilt.
B.  Die Rechnungshöhe ist multimodal.
C.  Die Rechnungshöhe ist normalverteilt.
D.  Die Rechnungshöhe ist linksschief.
E.  Die Rechnungshöhe ist rechtsschief.

::: {.notes}
Die Rechnungshöhe hat eine Spitze, ist also unimodal. 
Sie fällt nach rechts hin flacher ab, als sie links steigt, somit ist 
sie ***rechtsschief (E)***. 
Bei (annähernder) Gleichverteilung wären alle Säulen etwa gleich hoch, die 
Normalverteilung ist symmetrisch.
:::

<!-- --->


### Variablentransformation {include-only=master}

Ggfs. können Variablen durch Transformationen (z.B. $\sqrt{()}, \ln(), \ldots$)^[Hinweis: $\sqrt{()}$ mit `sqrt()`, $\ln()$ mit `log()`] in Richtung einer symmetrischen Normalverteilung transformiert werden:

```{r histogramlog, fig.align="center", out.width="50%"}
gf_histogram( ~ sqrt(total_bill), # Quadratwurzel der Variable
              bins = 9,           # Anzahl Säulen
              data = tips)        # Datentabelle
```

<!-- --->


### Liniendiagramm {include-only=deprecated}

Visualisiert den (zeitlichen) Verlauf mindestens einer numerischen Variable.^[Erstellen mit `gf_line()`.]

```{r echo = FALSE, out.width = "60%", fig.align="center"}
library(xts)
data("co2")
co2 <- as.xts(co2)
autoplot(co2)
```

<!-- --->


### Verteilungsfunktion

Die **empirische Verteilungsfunktion**^[Neben der *empirischen* Verteilungsfunktion gibt es auch eine *theoretische* Verteilungsfunktion $F(x)$.] $F_n(x)$ gibt an, wie hoch der Anteil unter den $n$ Beobachtungen ist, die kleiner oder gleich $x$ sind:

\[F_n(x)=\frac{\text{Anzahl Beobachtungen }\leq x}{n}\]

```{r echo=FALSE, out.width = "50%", fig.align="center", cache=FALSE}
x <- -5:55
y <- pdata(~total_bill, q=x, data=tips)
gf_line(y ~ x) %>%
  gf_labs(title = "Verteilungsfunktion Rechnungshöhe",
          x= "x",
          y= TeX("$F_n(x)$"))
rm(x)
rm(y)
```


### Übung `r nextExercise()`: Verteilungsfunktion {.exercise type=A-B-C answer=C}

Für die Rechnungshöhe gilt: $F_n(10)=`r round(pdata( ~total_bill, q=10, data = tips),2)`$:

```{r pdata}
pdata( ~ total_bill, q = 10, data = tips)
```


Welche Aussage stimmt?

A.  Die relative Häufigkeit einer Rechnungshöhe von $10\,\$$ liegt bei 
    $`r round(pdata( ~total_bill, q=10, data = tips),2)`$.
B.  Die relative Häufigkeit einer Rechnungshöhe von mindestens $10\,\$$ 
    liegt bei $`r round(pdata( ~total_bill, q=10, data = tips),2)`$.
C.  Die relative Häufigkeit einer Rechnungshöhe von höchstens $10\,\$$ liegt 
    bei $`r round(pdata( ~total_bill, q=10, data = tips),2)`$.

::: {.notes}
Die (empirische) Verteilungsfunktion sagt aus, wie groß der Anteil der 
Beobachtungen ist, die $\leq x$ sind, also ***C***.
Damit liegt die relative Häufigkeit einer Rechnungshöhe *über* $10\,\$$ bei 
$1 - F_n(10)=`r 1-round(pdata( ~total_bill, q=10, data = tips),2)`$.
:::


### Cartoon: Achsenbeschriftung und Skalierung {include-only=deprecated}

```{r echo=FALSE, out.width = "50%", fig.align="center", cache=FALSE}
# Lizenzworkaround: 
extern_image_include("https://www.causeweb.org/cause/sites/default/files/caption_contest/2017/Caption-Contest_09-2017.jpg", "cartoon0917.jpg", pathToImages)
```
"Beschrifte die Achsen!"^[[https://www.CAUSEweb.org/](https://www.causeweb.org/cause/caption-contest/september/2017/results) &copy; J.B. Landers, Überschrift K. Falbo]


### Lagemaße

Lagemaße sollen u.a. die zentrale Tendenz der Daten beschreiben:

- **Minimum** bzw. **Maximum**: kleinste bzw. größte Merkmalsausprägung.
- **Modus**/ Modalwert: häufigste Merkmalsausprägung.
- **Median**/ Zentralwert: Merkmalsausprägung, die bei (aufsteigend) sortierten 
  Beobachtungen in der Mitte liegt.
- **Arithmetischer Mittelwert** (engl. mean)^[Darüber hinaus gibt es noch den geometrischen und den harmonischen Mittelwert.]: Summe aller Beobachtungswerte $x_i$ geteilt durch die Anzahl Beobachtungen $n$: $\bar{x}=\frac{1}{n}\sum_{i=1}^n x_i$.
- **Quantil**: Das p-Quantil ist der Wert, für den gilt, dass er von p Prozent 
  der Beobachtungen nicht überschritten wird.
- **Quartile**: Q1 = 25%-Quantil, Q2 = 50%-Quantil, Q3 = 75%-Quantil.


### Übung `r nextExercise()`: Lagemaße {.exercise type=yesno answer=yes}

Stimmt die Aussage: Die Berechnung des arithmetischen Mittelwertes ist bei 
nominalen Merkmalen *nicht* sinnvoll?

- Ja.
- Nein.

::: {.notes}
***Ja***, da Sie mit nominalskalierten Daten *nicht* rechnen können. 

Dies gilt auch wenn nominale Daten numerisch, d.h. als Zahlen kodiert werden. 
Was soll z.B. eine durchschnittliche Telefonnummer sein?
:::

### Übung `r nextExercise()`: Lagemaße Kursgröße Dozentin {.exercise type=type=A-B-C-D answer=B}

Eine Dozentin unterrichtet $4$ kleine Kurse mit je $15$ Studierenden und einen 
großen Kurs mit $90$ Studierenden.

Wie groß ist der arithmetische Mittelwert der Kursgröße für die Dozentin?

A.  15
B.  30
C.  60
D.  90

::: {.notes}
Für die Dozentin gilt:

$$\bar{x}=\frac{4\cdot15+1\cdot90}{4+1}=\frac{150}{5}=30,$$

also ***B***.

Die Dozentin blickt von *oben* auf die 5 Kurse, sie sieht die kleinen Kurse und den großen Kurs gleich.
:::

### Übung `r nextExercise()`: Lagemaße Kursgröße Studierende {.exercise type=type=A-B-C-D answer=C}

Eine Dozentin unterrichtet $4$ kleine Kurse mit je $15$ Studierenden und einen 
großen Kurs mit $90$ Studierenden.

Mit wie vielen Kommiliton\*innen sitzt jede(r) Studierende(r) (einschließlich sich selbst) durchschnittlich in einem Kurs?

A.  15
B.  30
C.  60
D.  90

::: {.notes}
Für die Studierenden gilt:

$$\bar{x}=\frac{4\cdot 15 \cdot 15 +1\cdot 90 \cdot90}{4\cdot 15+1 \cdot 90}=\frac{9000}{150}=60,$$
also ***C***.

Von den 150 Studierenden erleben 90 den großen Kurs und 60 die kleinen Kurse.

Bei Mittelwerten, Anteilen usw. immer überlegen: der Anteil *wovon*, 
d.h., was ist die Beobachtungseinheit.

Anregung: [https://askgoodquestions.blog/2019/08/05/5-below-average-joke/](https://askgoodquestions.blog/2019/08/05/5-below-average-joke/)
:::


### Beispielrechnung Lagemaße

Daten: $20;18;24;40;24;22;21;23;20;28$ ($n=10$)

- Minimum, Maximum, Modus: $x_{min}=18,x_{max}=40, \quad x_{mod}=\{20;24\}$
- Median: $18; 20; 20; 21; \underbrace{22; 23}_{x_{0,5}=\frac{22+23}{2}=22.5}; 24; 24; 28; 40$
- Arithmetischer Mittelwert: $\bar{x}=\frac{1}{10}(20+18+24+\cdots+28)=\frac{240}{10}=24$
- $25\,\%$-Quantil:^[Hier sind verschiedene Berechnungen möglich. R gibt z.B. $20.25$ aus.] $x_{0,25}=20$


### Beispiel Quantil

Das $90\,\%$-Quantil der Rechnungshöhe liegt bei 
$`r round(quantile( ~total_bill, probs=0.9, data = tips),digits=2)`\,\$$:

```{r qdata}
qdata( ~ total_bill, p = 0.9, data = tips)
```

- $90\,\%$ der Rechnungen sind kleiner oder gleich $`r round(quantile( ~total_bill, probs=0.9, data = tips), digits=2)`\,\$$.
- $1-90\%=10\,\%$ der Rechnungen sind größer oder gleich $`r round(quantile( ~total_bill, probs=0.9, data = tips), digits=2)`\,\$$.


### Übung `r nextExercise()`: Lagemaße {.exercise type=yesno answer=yes}

Stimmt die Aussage: Der Median ist das $50\,\%$-Quantil einer Verteilung?

- Ja.
- Nein.

::: {.notes}
***Ja***, der Median ist der Wert, der von $50\,\%$ der Beobachtungen nicht 
überschritten wird.
:::


### Übung `r nextExercise()`: Lagemaße {.exercise type=yesno answer=no}

Stimmt die Aussage: Es gilt immer $F_n(\bar{x})=0.5$?

- Ja.
- Nein.

::: {.notes}
***Nein***, während für den Median nach Definition gilt $F_n(x_{0,5})=0.5$, gilt 
dies für den Mittelwert beispielsweise bei symmetrischen Verteilungen, aber 
nicht z.B. bei schiefen Verteilungen.
::: 


### Übung `r nextExercise()`: Vergleich Median und Mittelwert {.exercise type=A-B-C answer=C}

```{r echo=FALSE, out.width = "60%", fig.align="center"}
set.seed(1896)
xsym <- rnorm(1000)
xls <- 1 - rchisq(1000, 2)
xrs <- rchisq(1000, 2)

hls <- gf_histogram( ~ xls, 
                     xlab  = NULL, 
                     title = "A", 
                     fill  = pal_npg()(1), 
                     color = "darkgrey") %>% 
         gf_theme(axis.text.x = element_blank())

hsym <- gf_histogram( ~ xsym, 
                      xlab  = NULL, 
                      title = "B", 
                      fill  = pal_npg()(1), 
                      color = "darkgrey") %>% 
          gf_theme(axis.text.x = element_blank())

hrs <- gf_histogram( ~ xrs, 
                     xlab  = NULL, 
                     title = "C", 
                     fill  = pal_npg()(1), 
                     color = "darkgrey") %>% 
         gf_theme(axis.text.x = element_blank())

grid.arrange(hls, hsym, hrs, nrow = 3)
```

Für welche Abbildung gilt wohl Median $<$ arithmetischer Mittelwert?

A.  Abbildung A.
B.  Abbildung B.
C.  Abbildung C.


:::::: {.notes} 
Der Mittelwert ist i.d.R. in Richtung "des langen Endes" einer Verteilung 
verschoben, daher ***C***. 
Häufig, aber nicht immer:

::: {.small}

 Linksschief              Symmetrisch                  Rechtschief
----------------------  ----------------------------  -----------------------
Mittelwert $<$ Median    Mittelwert $\approx$ Median   Mittelwert $>$ Median

:::

Bei (sehr) schiefen Daten beschreibt der Median (blau, gestrichelt) den 
Schwerpunkt der Beobachtungen besser als der arithmetische Mittelwert (rot).


```{r echo=FALSE, out.width = "40%", fig.align="center"}
hls <- gf_histogram( ~ xls, 
                     xlab = NULL, 
                     title = "A", 
                     fill = pal_npg()(1), 
                     color = "darkgrey") %>% 
      gf_theme(axis.text.x = element_blank()) %>%
      gf_vline(xintercept = ~median(xls), 
               color = pal_npg()(1), 
               linetype = "dashed") %>%
      gf_vline(xintercept = ~mean(xls), 
               color = "red") 

hsym <- gf_histogram( ~ xsym, 
                      xlab = NULL, 
                      title = "B", 
                      fill = pal_npg()(1), 
                      color = "darkgrey") %>% 
        gf_theme(axis.text.x = element_blank()) %>%
        gf_vline(xintercept = ~median(xsym), 
                 color = pal_npg()(1), 
                 linetype = "dashed") %>%
        gf_vline(xintercept = ~mean(xsym), 
                 color = "red") 

hrs <- gf_histogram( ~ xrs, 
                     xlab = NULL, 
                     title = "C", 
                     fill = pal_npg()(1), 
                     color = "darkgrey") %>%
       gf_theme(axis.text.x = element_blank()) %>%
       gf_vline(xintercept = ~median(xrs), 
                color = pal_npg()(1), 
                linetype = "dashed") %>%
       gf_vline(xintercept = ~mean(xrs), 
                color = "red") 

grid.arrange(hls, hsym, hrs, nrow = 3)

rm(xsym)
rm(xls)
rm(xrs)
```

::::::


### Beispiel: Value at Risk {include-only=deprecated}

- Der Value-at-Risk (VaR) ist ein Risikomaß im Finanzsektor (z.B. Basel, Solvency II): 
  Der Value-at-Risk zum Niveau $\alpha$ ist das $\alpha$ Quantil der Vermögensänderung^[Eine praktische Herausforderung ist u.a. das Bestimmen dieser Quantile. In der Regel wird der Verlust mit positiven Vorzeichen oder prozentualer Veränderung angegeben.], d.h., mit einer Wahrscheinlichkeit von $1-\alpha$ ist der *Verlust* nicht größer.^[Für eine Diskussion siehe z.B.  Ziggel, D., Berens, T. (2014): Risikomessung mit dem Expected Shortfall, Risiko Manager 1/2014, S. 27--30.] 

- $VaR_{5\%}=(-)5000000\oureuro$: Mit einer Wahrscheinlichkeit von $1-5\%=95\%$ ist 
  der Verlust nicht größer als $5000000\oureuro$ -- er könnte aber in maximal $5\,\%$ 
  der Fälle größer sein.

- $VaR_{1\%}=(-)7500000\oureuro$: Mit einer Wahrscheinlichkeit von $1-1\%=99\%$ ist 
  der Verlust nicht größer als $7500000\oureuro$ -- er könnte aber in maximal $1\,\%$ 
  der Fälle größer sein.


### Mittelwert als "Modell"


[Idee:]{.cemph} 
$$\text{Daten } = \text{ Modell } + \text{ Rest}.$$

```{r}
mean( ~ total_bill, data = tips)
```


- Für Beobachtung $i$ gilt: $x_i = \bar{x} + (x_i-\bar{x})$.

- Der "Rest" $x_i-\bar{x}$ beschreibt die Abweichung^[Zur Einschätzung, ob die Abweichung groß oder klein ist, wird die Streuung (s.u.) der Daten herangezogen.] der Beobachtung zum Mittelwert $\bar{x}$ (hier: "Modell").


### Mittelwert als "Modell" -- Was heißt das konkret? {exclude-only=exclude-crazy-norman}

```{r setup_mean_model, echo=FALSE, }
my.model.mean.f <- mean( ~ total_bill, data = tips)
my.model.mean.sumofsq <- (nrow(tips)-1) * var( ~ total_bill, data = tips)
```


*Was haben wir nun?* -- **Ein erstes Modell!**

Im Allgemeinen suchen wir (mathematisch gesprochen) nach einer Funktion $f$, 
welche eine Beziehung zwischen den Daten $x$ und $y$, bis auf einen 
Fehlerterm $\varepsilon$, darstellt: 

$y = f(x) + \varepsilon$

Unsere aktuelle Schätzung für $f$ ist der Mittelwert der $y_i$ und lautet daher:
$\hat{f}(x)=`r my.model.mean.f`$

Damit können wir auch für jedes $x$ eine Schätzung für $y$ abgeben:
$\hat{y} = \hat{f}(x) = `r my.model.mean.f`$

Für alle bekannten Datenpunktpaare ($x_i$, $y_i$) können wir jeweils auch den 
*Rest* als Fehlerterm bestimmen:
$e_i = y_i - \hat{y}_i =  y_i - \hat{f}(x_i) = y_i - `r my.model.mean.f`$

Daher können wir den gesamten "Rest" wie folgt beziffern:
$\sum_{i=1}^{n} e_i^2 = `r sprintf("%.2f", my.model.mean.sumofsq)`$

<!-- -->

### Sebastians Kaffeemühle {include-only=deprecated}

```{r echo=FALSE, out.width = "20%", fig.align="right"}
knitr::include_graphics(file.path(pathToImages, "maschine.jpg"), error=FALSE)
```


Der Kaffee ist der Mittelwert plus irgendein Rest: Zufall?^[Skizze: Sebastian Sauer] 


### Arithmetischer Mittelwert und Median {exclude=qmwinf,eufom}

- Der arithmetische Mittelwert minimiert die Summe der quadratischen Abweichungen der Beobachtungen von einer Zahl $c$: $\bar{x}=\underset{c}{\arg \min} \sum_i^n(x_i-c)^2$. Er ist der Durchschnitt in dem Sinne, dass alle Merkmalsträger den gleichen Anteil an der Merkmalssumme haben.

- Der Median minimiert die Summe der absoluten Abweichungen der Beobachtungen von einer Zahl $c$: $x_{0,5}=\underset{c}{\arg \min} \sum_i^n|x_i-c|$. Er ist die Merkmalsausprägung eines (im Sinne des Merkmals) typischen, d.h. mittleren Merkmalsträgers. 

- Der Median ist robust gegen Ausreißer, der arithmetische Mittelwert nicht. D.h.,  $\bar{x}$ kann stark durch einzelne extreme Werte verändert werden, $x_{0,5}$ nicht.^[[https://twitter.com/annaegalite/status/1166446645204213760](https://twitter.com/annaegalite/status/1166446645204213760)]

:::{.footnotesize}
[Hinweis:]{.cemph} Sei $f(x)=x^2+1$, dann ist $\underset{x}{\min} f(x)=1$ und $\underset{x}{\arg \min} f(x)=0$.
:::


### Abweichungen vom Mittelwert summieren sich zu Null auf

```{r fig-abw-balken-mw, echo = FALSE, out.width="60%"}

d <- tibble::tribble(
  ~id, ~note, ~note_avg, ~delta, ~note2, ~note_avg2,
   1L,     2,     2.325, -0.325,  2.325,          2,
   2L,   2.7,     2.325,  0.375,    2.7,      2.325,
   3L,   3.1,     2.325,  0.775,    3.1,      2.325,
   4L,   1.5,     2.325, -0.825,  2.325,        1.5
  )


d <- d %>% 
  mutate(delta_abs = abs(delta),
         pos = ifelse(delta > 0, "positiv", "negativ"),
         delta_sq = delta^2)


dmn <- mean(d$note)

d %>%
  ggplot(aes(x = id, 
             y = note)) +
  geom_hline(yintercept = dmn, 
             linetype = "dashed") +
  geom_segment(aes(y = dmn,
                   yend = note,
                   x = id,
                   xend = id,
                   linetype = pos)
               ) +
  geom_point(size = 5) + 
  labs(linetype = "Richtung der Abweichung") +
  theme(legend.position =  c(1, 1),
        legend.justification = c(1, 1)) +
  annotate(geom = "label",
           x = 0,
           hjust = 0,
           y = dmn, 
           label = paste0("MW = ", round(dmn, 2))) +
  scale_y_continuous(limits = c(1, 4)) +
  labs(x = "",
       y = "") +
  scale_x_continuous(breaks = 1:4) -> p_mean_deltas

p_mean_deltas
```

$$\sum_{i=1}^n (x_i-\bar{x})=\sum_{i=1}^n x_i - \sum_{i=1}^n \bar{x} = n\cdot \bar{x} - n\cdot \bar{x}=0$$

### Übung `r nextExercise()`: Variation {.exercise type=type=A-B-C answer=A}


```{r, out.width="55%", echo = FALSE, fig.align='center'}
set.seed(1896)
x <- scale(rnorm(10))

daten <- data.frame(
  x = c(x*1/4, x),
  y = rep(0,2*10),
  sit = c(rep("A", 10),
          rep("B", 10))
)

mwplot <- ggplot(
  daten, aes(x, y)) +
  geom_point(size = 1.5) +
  geom_vline(xintercept = 0) +
  facet_wrap(vars(sit)) + theme(
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank()) +
  labs(x="", y="") +
  xlim(-3,3)

mwplot
```

In welcher Situation beschreibt der arithmetische Mittelwert (vertikale Linie) als Modell die Beobachtungen (Punkte) *besser*?


A.  Situation A.
B.  Situation B.
C.  In beiden Situationen gleich.

::: {.notes}

***A***: Der *Rest*, die Abweichung  $(x_i-\bar{x})$ zwischen *Modell* ($\bar{x}$) und den *Daten* bzw. Beobachtungen $x_i$ ist in *A* insgesamt kleiner als in *B*. Die $i=1,\ldots,n$ Beobachtungen streuen in *A* weniger um den Mittelwert als in *B*. 


*Hinweis*: In beiden Abbildungen wurde die gleiche Skalierung der Achse verwendet. 
:::




### Streuungsmaße

Streuungsmaße sollen die Streuung/ Variation der Daten beschreiben:


- **Varianz**: Maß für die durchschnittliche quadratische Abweichung zum Mittelwert: $s^2=\frac{1}{n-1}\sum_{i=1}^n (x_i-\bar{x})^2$. Diese hat aber eine andere Einheit als die Daten, z.B. Daten in $\euro$, Varianz $\euro^2$. Durch das Quadrieren werden Abweichungen zum Mittelwert nach oben oder unten gleich behandelt und größere Abweichungen stärker gewichtet.^[$1/n$ ist nicht falsch; $1/(n-1)$ ist aus Gründen, die außerhalb dieser Vorlesung liegen, besser, wenn von einer Stichprobe auf die Varianz der Population ($\sigma^2$) verallgemeinert werden soll. Der Unterschied ist bei großem $n$ klein.]

- **Standardabweichung** (engl. standard deviation): Quadratwurzel der Varianz: $sd=s=\sqrt{s^2}$

<!-- - **Variationskoeffizient**: erlaubt den Vergleich von Standardabweichungen bei verhältnisskalierten Variablen: $vc=\frac{sd}{\bar{x}}$ -->

- **Interquartilsabstand** (engl. interquartile range, IQR):  
oberes Quartil ($75\,\%$-Quantil, Q3) -- unteres Quartil ($25\,\%$-Quantil, Q1)

- **Spannweite** (engl. range): Maximum -- Minimum


### Sebastians Kaffeemühle {include-only=sesmill}

```{r echo=FALSE, out.width = "20%", fig.align="right"}
knitr::include_graphics(file.path(pathToImages, "maschine.jpg"), error=FALSE)
```

Streuungsmaße sagen, wie stark z.B. Kaffeebohnen variieren. Sind die Bohnen ca. 
gleich groß oder gibt es große Unterschiede? ^[Skizze: Sebastian Sauer]

### Übung `r nextExercise()`: Variation {.exercise type=type=A-B-C-D answer=A}

Markus befragt Samstag Vormittag in der Fußgängerzone Passant*innen nach ihrem 
Alter, Samira zur gleichen Zeit Studierende im FOM Studienzentrum.

Was gilt vermutlich für die Standardabweichung des Alters der Befragten?
 

A.  $sd_{\text{Markus}} > sd_{\text{Samira}}$
B.  $sd_{\text{Markus}} \approx sd_{\text{Samira}}$
C.  $sd_{\text{Markus}} < sd_{\text{Samira}}$
D.  Hängt davon ab, wer mehr Personen befragt.

::: {.notes}

***A***: Viele Studierende sind tendenziell ähnlich alt -- auch wenn es 
natürlich Ausnahmen gibt. Sie sind aber nur eine Teilmenge der 
Allgemeinbevölkerung -- auch bezüglich des Alters. 

Da die Standardabweichung so etwas wie der Mittelwert der Abweichung ist, 
hängt die Höhe nicht von der Anzahl der Beobachtungen ab.  

Anregung: [https://askgoodquestions.blog/2019/08/12/6-two-dreaded-words-part-1/](https://askgoodquestions.blog/2019/08/12/6-two-dreaded-words-part-1/)
:::


### Beispielrechnung Streuungsmaße

Daten: $20;18;24;40;24;22;21;23;20;28, \quad n=10, \quad \bar{x}=24$

- Varianz: $s^2=\frac{1}{10-1}\left((20-24)^2+(18-24)^2+\ldots +(28-24)^2 )\right)=\frac{354}{9} \approx 39{,}33$

- Standardabweichung: $sd = \sqrt{39,33} =6{,}27$

- Interquartilsabstand:^[Hier sind aufgrund verschiedener Berechnungsmöglichkeiten der Quantile unterschiedliche Werte möglich. R gibt z.B. $3.75$ aus.] $IQR=24-20=4$

- Spannweite: $40-18=22$.


### Varianz als "Abweichungsquadrate"

```{r delta-plot, echo = FALSE, fig.width = 9, out.width = "7cm", fig.asp = 0.8}

dmn <- mean(d$note)

d %>%   
  ggplot(aes(x = id, y = note)) +
  geom_hline(yintercept = dmn, linetype = "dashed") +
  geom_segment(aes(y = dmn,
                   yend = note,
                   x = id,
                   xend = id,
                   linetype = pos)) +
    annotate(geom = "label",
           x = 0,
           hjust = 0,
           y = dmn, 
           label = paste0("MW = ", round(dmn, 2))) +
  geom_rect(aes(ymin = note_avg2,
                ymax = note2,
                xmin = id,
                xmax = id+delta_abs),
            fill = pal_npg()(1),
            alpha = .5) +
  geom_text(aes(label=round(delta_sq,3)),
            hjust = "left", 
            nudge_x = 0.05,
            vjust = ifelse(d$pos == "positiv", "top", "bottom"),
            nudge_y = ifelse(d$pos == "positiv", -0.05, 0.05),
            color = pal_npg()(1),
            size = 6) +
  geom_point(size = 5) +
    labs(linetype = "Richtung der Abweichung",
         x = "",
         y = "") +
  theme(legend.position =  c(1, 1),
        legend.justification = c(1, 1)) +
  scale_y_continuous(limits = c(1, 5)) +
  scale_x_continuous(breaks = 1:4) -> p_mean_deltas_sq

p_mean_deltas_sq
```


::: {.small}

$$s^2 \approx \frac{1}{`r length(d$delta_sq)`- 1} \cdot \left( `r paste0(round(d$delta_sq,3), collapse=" + ")` \right) = `r round(1/(length(d$delta_sq)-1) * sum(d$delta_sq),3)`$$

:::

Abweichungsquadrate als Kennzahl für "Rest":

  - `Daten = Modell + Rest`: $x_i=\bar{x} + (x_i-\bar{x})$.
  
  - Quadratsumme des Restes: $\sum_{i=1}^n (x_i-\bar{x})^2=(n-1) \cdot s^2 = (n-1) \cdot sd^2$.


### Beispiel: Abwanderungserkennung 

Während Klaus sehr regelmäßig einkauft (kleine Streuung), kauft Gabi zwar genau 
so oft, aber unregelmäßiger ein:

```{r echo=FALSE, out.width = "50%", fig.align="center"}
gabi <- c(5, 25, 2, 3, 30, 15, 5, 20, 35, 10)
klaus <- c(13, 15, 14, 14, 16, 15, 16, 15, 16, 16)
kaufdaten <- data.frame(Zeitpunkte = c(cumsum(gabi), cumsum(klaus)), 
                        Personen = c(rep("Gabi", length(gabi)), rep("Klaus", length(klaus))))
gf_point(Personen ~ Zeitpunkte, 
         data = kaufdaten, 
         size = 3, 
         color = pal_npg()(1))

rm(gabi)
rm(klaus)
rm(kaufdaten)
```

Beide waren seit 30 Tagen nicht mehr einkaufen: Aufgrund der größeren Streuung 
der Kaufintervalle ist dies bei Gabi *üblicher* als bei Klaus.^[Vgl. z.B. Papenhoff, H., Lübke, K. (2017): Churn Management – Herausforderungen für den Handel, in: Helmke, S. et al. (Hg.) Effektives Customer Relationship Management, S. 161--170.]


### Übung `r nextExercise()`: z-Wert {.exercise type=A-B-C answer=B}

**z-Transformation** (Studentisierung): Überführung einer Verteilung in eine 
mit $\bar{z}=0$ und $sd_z=1$: $$z_i=\frac{x_i-\bar{x}}{sd_x}$$

Kunde A hat bei 30 Tagen ohne Einkauf einen z-Wert von $1$, Kunde B einen 
von $2$. 
Welcher Kunde ist abwanderungsgefährdeter?

A.  A
B.  B
C.  Kann mit der gegebenen Information nicht entschieden werden.

::: {.notes}

***B***: Der Zähler $x_i-\bar{x}$ gibt an, ob der Wert $x_i$ über oder unter 
dem (jeweiligen) Mittelwert $\bar{x}$ liegt. 
Durch die Standardisierung (Division durch die jeweilige $sd_x$) wird die 
Abweichung zum Mittelwert *relativiert*: Wie groß ist die Abweichung? 
Die Abweichung zum Mittelwert ist bei B (relativ) größer: 
Während die Dauer der Abwesenheit von A eine Standardabweichung über seinem 
Mittelwert liegt, liegt diese bei B zwei Standardabweichungen über 
dem Mittelwert. 

*Hinweis*: z.B. Befehl `zscore()`.

:::

### Übung `r nextExercise()`: Streuungsmaße {.exercise type=A-B-C answer=B}

Welche Aussage stimmt?

A.  Die Standardabweichung ist robuster (gegen Ausreißer) als der Interquartilsabstand.
B.  Der Interquartilsabstand ist robuster (gegen Ausreißer) als die Standardabweichung.
C.  Interquartilsabstand und Standardabweichung sind gleich robust gegen Ausreißer.

::: {.notes}
Antwort ***B*** ist korrekt. Ausreißer sind entweder extrem große oder extrem 
kleine Werte. z.B. würde sich im voranstehenden Beispiel der IQR nicht ändern, 
wenn der höchste Wert ($40$) auf $80$ verdoppelt würde (Ausreißer nach oben). 
Die Varianz hingegen würde sich vergrößern und somit auch 
die Standardabweichung.
:::


### Übung `r nextExercise()`: Vergleich Streuung {.exercise type=A-B-C answer=C}

```{r echo=FALSE, out.width = "60%", fig.align="center", message=FALSE}
set.seed(1896)
xs1 <- rnorm(1000)
xs2 <- rnorm(1000, sd = 2)
xs3 <- runif(1000, -6, 6)

hs1 <- gf_histogram( ~ xs1, 
                     xlab  = NULL, 
                     title = "A", 
                     fill  = pal_npg()(1), 
                     color = "darkgrey") %>% 
       gf_lims(x=c(-6,6))

hs2 <- gf_histogram( ~ xs2, 
                     xlab  = NULL, 
                     title = "B", 
                     fill  = pal_npg()(1), 
                     color = "darkgrey") %>% 
       gf_lims(x=c(-6,6))

hs3 <- gf_histogram( ~ xs3, 
                     xlab  = NULL, 
                     title = "C", 
                     fill  = pal_npg()(1), 
                     color = "darkgrey") %>% 
       gf_lims(x=c(-6,6)) +
       scale_y_continuous(breaks=c(20, 40), labels = c("  20", "  40"))


grid.arrange(hs1, hs2, hs3, nrow = 3)

rm(xs1)
rm(xs2)
rm(xs3)
```

Bei welcher Abbildung ist die Standardabweichung $sd$ wohl am größten?

A.  Abbildung A.
B.  Abbildung B.
C.  Abbildung C.


::: {.notes} 
***C***: Hier liegen mehr Beobachtungen weiter vom Mittelwert entfernt als 
bei *B*. 
(Die Beobachtungen in *B* streuen auch mehr als die Werte in *A*.) 
Relevant ist die Variation der Werte ($x$-Achse), nicht 
der Häufigkeit ($y$-Achse).
:::


<!-- -->

### Offene Übung `r nextExercise()`: Kennzahlen {.exercise type=essay exclude=qmwinf,eufom,master}

Bilden Sie Gruppen von 4-8 Personen und analysieren Sie die Anzahl Stunden, 
die Sie heute Nacht geschlafen haben. Berechnen Sie arithmetischen Mittelwert, 
Median und Standardabweichung.^[Aus Datenschutzgründen dürfen Sie lügen!]

::: {.notes}
*Individuell*
:::

<!-- -->




### Offene Übung `r nextExercise()`: Skalenniveaus {.exercise type=essay}

Welche Lage- und Streuungsmaße sind zulässig? 

+---------------------+---------------------+--------------------------------+
| **Skalenniveau**    | **Lagemaße**        | **Streuungsmaße**              |
+=====================+=====================+================================+
| **Nominal**         |                     |                                | 
+---------------------+---------------------+--------------------------------+
| **Ordinal**         |                     |                                |
+---------------------+---------------------+--------------------------------+
| **Metrisch**        |                     |                                | 
+---------------------+---------------------+--------------------------------+


::: {.notes}

+---------------------+---------------------+-------------------------------------+
| **Skalenniveau**    | **Lagemaße**        | **Streuungsmaße**                   |
+=====================+=====================+=====================================+
| **Nominal**         | Modus               | *Entropie* (hier nicht behandelt)   | 
+---------------------+---------------------+-------------------------------------+
| **Ordinal**         | \+ Quantile, Median | (Spannweite, IQR)                   |
+---------------------+---------------------+-------------------------------------+
| **Metrisch**        | \+ Mittelwert       | \+ Varianz, Standardabweichung      | 
+---------------------+---------------------+-------------------------------------+

:::


### Trinkgeld-Datentabelle {.shrink}

`inspect()` *inspiziert* die Datentabelle und gibt eine Übersicht über 
wesentliche Kennzahlen.

```{r Trinkgelddaten_inspect_command, eval=FALSE}
inspect(tips)
```

::: {.scriptsize}
```{r  Trinkgelddaten_inspect_output, echo=FALSE}
options(width = 150)
opts_chunk$set(comment = "", warning = FALSE, message = FALSE, echo = TRUE, size="small")
(insp <- mosaic::inspect(tips))
```
:::


### Übung `r nextExercise()`: Metrische Variablen {.exercise type=A-B-C-D-E answer=B}

Wie viele metrische Variablen liegen vor?

A.  2
B.  3
C.  4
D.  7
E.  244

::: {.notes}
Es liegen ***`r nrow(insp[[2]])` (Antwort B)*** metrische (numerische) 
Variablen vor (`total_bill`, `tip`, `size`), die anderen sind kategoriale 
(bzw. nominalskalierte) Variablen. 
`r nrow(insp[[1]]) + nrow(insp[[2]])` ist die Gesamtzahl an Variablen und 
`r insp[[1]]$n[1]` ist die Anzahl der Beobachtungen.
:::


### Kennzahlen Rechnungshöhe

Analysiere über Kennzahlen:


```{r favstats}
favstats( ~ total_bill, # Variable, die analysiert wird
          data = tips)  # Datentabelle
```


### Übung `r nextExercise()`: Kennzahlen {.exercise type=essay}

```{r favstats}
```

In welchem Bereich liegen $50\,\%$ der Beobachtungen der Rechnungshöhe?

::: {.notes}
Die mittleren $50\,\%$ liegen im Bereich `Q1` bis `Q3`. 
Dies sind die Beobachtungswerte innerhalb des Interquartilsabstands (IQR). 
Aber auch zwischen `min` und `median` bzw. zwischen `median` und `max` 
(jeweils einschließlich) liegen $50\,\%$ der Beobachtungen.
:::

<!-- -->


### Boxplot

Visualisiert die Verteilung von deskriptiven Kennzahlen und mögliche Ausreißer 
einer numerischen Variable.

```{r out.width = "55%", fig.align="center"}
gf_boxplot(tip ~ 1, data = tips)
```


### Anatomie Boxplot

- Die untere Linie der Box ist das untere Quartil ($25\,\%$-Quantil, Q1).

- Die obere Linie der Box ist das obere Quartil ($75\,\%$-Quantil, Q3).

- Die Linie in der Box (gelegentlich auch Punkt) ist der Median.

- Sollten Punkte außerhalb der Antennen sein, sind dies mögliche Ausreißer. Maximale Reichweite der Antennen: Bis zu der Beobachtung, die maximal $1.5 \cdot IQR$ vom oberen bzw. unteren Quartil entfernt liegt. Sollte das Maximum der Daten kleiner bzw. das Minimum größer sein, wird dieses genommen.^[Definition nicht immer einheitlich.]

<!-- -->


### Offene Übung `r nextExercise()`: Boxplot {.exercise type=essay}

Verbinde Abbildung und Kennzahlen. Ab wann ist eine Beobachtung ein potentieller Ausreißer nach oben?

```{r, echo=FALSE, out.width = "60%", fig.align="center", fig.asp=0.6}
set.seed(1896)
chi <- data.frame(x = rchisq(100, 3))
gf_boxplot(1 ~ x, data = chi, 
            ylab = element_blank()) %>% 
  gf_theme(axis.ticks.y = element_blank(), 
           axis.text.y = element_blank())

(stats <- round(favstats(~x, data = chi), 2))
```

::: {.notes}
Es ist $IQR = `r stats$Q3`-`r stats$Q1`=`r stats$Q3-stats$Q1`$ und $1.5 \cdot IQR = `r (IQR15 <- round((stats$Q3-stats$Q1)*1.5,2))`$. Die obere Antenne liegt daher bei $`r stats$Q3` + `r IQR15` = `r (upwsk <- stats$Q3+IQR15)`$. Also können Werte als Ausreißer nach oben gelten, wenn sie größer als $`r upwsk`$ sind.
:::

<!-- -->


### Violinplot {include-only=deprecated}

Auch eine Möglichkeit zur Darstellung einer Verteilung ist der Violinplot `gf_violin()`:

```{r violin-box, fig.align="center", out.width="60%", echo=FALSE}
p1 <- gf_boxplot(tip ~ 1, data = tips) %>% gf_rug()
p2 <- gf_violin(tip ~ 1, data = tips) %>% gf_rug()
gridExtra::grid.arrange(p1,p2, nrow = 1)
```

<!-- -->

### Rechnungshöhe gruppiert nach Geschlecht {include-only=deprecated}

Histogramm gruppiert nach Geschlecht:

```{r histogram_group, fig.align="center", out.width="60%"}
 gf_histogram( ~ total_bill # Variable, die analysiert wird
               | sex,       # Variable, nach der gruppiert wird
               bins = 9,    # Anzahl Säulen
               data = tips) # Datentabelle
```

<!-- -->



### Offene Übung `r #nextExercise()`: Gruppierter Boxplot {.exercise type=essay include-only=deprecated}

Erstellen Sie einen Boxplot der Rechnungshöhe gruppiert nach 
Raucher/ Nichtraucher. 
Zur Erinnerung: Formeln werden mit `y ~ x | z` eingegeben, also ggf. abhängige 
Variable $y$ in Abhängigkeit von unabhängiger Variable $x$ ggf. bedingt durch 
oder gruppiert nach $z$.

::: {.notes}

`gf_boxplot(total_bill ~ smoker, data = tips)`

oder

`gf_boxplot( ~ total_bill |  smoker, data = tips)`

oder

`gf_boxploth(smoker ~ total_bill, data = tips)`


:::

<!-- -->


### Boxplot Rechnungshöhe abhängig vom Geschlecht

Analysiere über Boxplot:

```{r boxplot-group, fig.align="center", out.width="50%"}
gf_boxplot(total_bill ~ # abhängige Variable
          sex, # unabhängige Variable 
          data = tips) # Datentabelle
```

<!-- -->


### Übung `r nextExercise()`: Übung Boxplot {.exercise type=A-B-C-D answer=C}

```{r boxplot-group, echo=FALSE, fig.align="right", out.width="20%"}
```

Welche Aussage stimmt nach der Abbildung?

A.  Der Mittelwert der Rechnungshöhe ist bei den Männern unter $20\,\$$.
B.  Der Mittelwert der Rechnungshöhe ist bei den Männern über $20\,\$$.
C.  Der Median der Rechnungshöhe ist bei den Männern unter $20\,\$$.
D.  Der Median der Rechnungshöhe ist bei den Männern über $20\,\$$.

::: {.notes}
Die Mittelwerte werden in diesen Boxplots nicht mit ausgegeben, daher können 
die Antworten A und B nicht beurteilt werden. 
Der Median (die Linie in der Box) liegt bei den Männern noch knapp unter 
$20\,\$$, somit ist Antwort ***C*** korrekt.
:::


### Kennzahlen/ Diagramme gruppiert nach Geschlecht

Zusammenfassende Kennzahlen der Rechnungshöhe je Geschlecht:^[Alternative: `favstats( ~ total_bill | sex, data = tips)`] 

```{r}
favstats(total_bill ~ sex, data = tips) 
```

Zusammenfassendes Diagramm je *Mittelwert* von Geschlecht:

```{r fig.width = 6, out.width="6cm", fig.asp = 0.6}
gf_point(total_bill ~ sex, stat = "summary", size = 5, data = tips)
```



### Sebastians Kaffeemühle {include-only=sesmill}

```{r echo=FALSE, out.width = "20%", fig.align="right"}
knitr::include_graphics(file.path(pathToImages, "maschine.jpg"), error =FALSE)
```

Vielleicht kommt bei unterschiedlichen Bohnen auch unterschiedlicher 
Kaffee raus?^[Skizze: Sebastian Sauer]


### Modellierung (I/ II)

[Idee:]{.cemph}

$$\text{Daten } = \text{ Modell } + \text{ Rest}$$

[Modell:]{.cemph} Gesamtmittelwert $\bar{x}$, d.h. keine die Rechnungshöhe 
modellierende Variable^[Dies kann in `mosaic` auch durch `y ~ 1` geschrieben werden]:


```{r}
favstats(total_bill ~ 1, data = tips)
```

```{r, include=FALSE}
f1 <- favstats(total_bill ~ 1, data = tips)
```

$$\sum_{i=1}^n(x_i-\bar{x})^2=(n-1) \cdot sd^2=(`r f1["n"]`-1) \cdot `r f1["sd"]`^2=`r sprintf("%.2f", (f1["n"]-1)*f1["sd"]^2)`.$$

### Modellierung (II/ II) 

[Modell:]{.cemph} Gruppenmittelwert $\bar{x}_j$ je Anzahl Personen 
$j=1, \ldots, 6$, d.h., die Rechnungshöhe wird durch die jeweilige Anzahl 
Personen modelliert:

::: {.scriptsize}
```{r}
favstats(total_bill ~ size, data = tips)
```
:::
```{r, include=FALSE}
f2 <- favstats(total_bill ~ size, data = tips)
```

$$\sum_{j=1}^K \sum_{i=1}^{n_j}(x_{i,j}-\bar{x}_j)^2=\sum_{j=1}^6 (n_j-1) \cdot sd_j^2=`r sprintf("%.2f", sum((f2[,"n"]-1)*f2[,"sd"]^2))`$$

Bei der Analyse `total_bill ~ size` ist der *Rest* kleiner als bei der 
Analyse `total_bill ~ 1` (ohne erklärende Variable).

Für diese Reduzierung des Restes wird ein Preis gezahlt: 
In den einzelnen Gruppen sind weniger Beobachtungen: 
weniger *Freiheitsgrade* (engl: degrees of freedom, df).


### Gruppenmittelwerte als "Modell" -- Was heißt das konkret? {exclude-only=exclude-crazy-norman}

```{r setup_groupmean_model, echo=FALSE, }
my.model.groupmean.f <- mean(total_bill ~ size, data = tips)
my.model.groupmean.sumofsq <- sum((favstats(total_bill ~ size, data = tips)$n - 1) * var(total_bill ~ size, data = tips))

my.model.groupmean.text <- "7.242  & : x_{size} =  1\\\\\n 16.448  & : x_{size} =  2\\\\\n 23.278  & : x_{size} =  3\\\\\n 28.614  & : x_{size} =  4\\\\\n 30.068  & : x_{size} =  5\\\\\n 34.83  & : x_{size} =  6\n"
```

::: {.small}

*Was haben wir nun?* -- **Ein neues Modell!**

Unsere aktuelle Schätzung für $f$ ist nun, abhängig von der Tischgröße, 
der jeweilige Gruppenmittelwert.



:::::: {.columns}
::: {.column width="60%"}

Damit können wir für jedes $x$ eine Schätzung für $y$ abgeben, jeweils in 
Abhängigkeit von der Tischgröße $x_{size}$: $$\hat{y} = \hat{f}(x)$$

Für alle bekannten Datenpunktpaare ($x_i$, $y_i$) lässt sich der *Rest* als 
Fehlerterm bestimmen: $$e_i =  y_i - \hat{y}_i = y_i - \hat{f}(x_i)$$

Daher können wir den gesamten "Rest" wie folgt beziffern:

:::
::: {.column width="40%"}

$$\hat{f}(x) \approx \begin{cases}
7.242  & : x_{size} =  1\\ 16.448  & : x_{size} =  2\\ 23.278  & : x_{size} =  3\\ 28.614  & : x_{size} =  4\\ 30.068  & : x_{size} =  5\\ 34.83  & : x_{size} =  6\end{cases}$$

:::
::::::

$$\sum_{i=1}^{n} e_i^2 = \sum_{j=1}^{K} (n_j-1) \cdot s_j^2 = \sum_{j=1}^{6} (n_j-1) \cdot sd_j^2= `r sprintf("%.2f", my.model.groupmean.sumofsq)`$$

:::
<!-- -->


### Abbildung Modellierung

Visualisierung für die reduzierten Datentabelle mit nur 1 oder 6 Personen am 
Tisch (`size`).^[Quelle: [https://data-se.netlify.com/2019/03/26/reducing-residual-variance-in-modeling/](https://data-se.netlify.com/2019/03/26/reducing-residual-variance-in-modeling/)]

```{r out.width = "65%", fig.align="center", fig.asp=0.5, echo=FALSE}

tips2 <- tips %>%
  filter(size %in% c(1, 6)) %>% 
  mutate(ID = 1:nrow(.),
         total_bill_resid = total_bill - mean(total_bill),
         total_bill_resid_quad = total_bill_resid^2) %>% 
  group_by(size) %>% 
  mutate(total_bill_mean_group = mean(total_bill)) %>% 
  ungroup()


tips_sum <- tips2 %>% 
  group_by(size) %>% 
  summarise(total_bill = mean(total_bill)) %>% 
  ungroup()


p1 <- tips2 %>% 
  ggplot() +
  geom_hline(aes(yintercept = mean(total_bill)), size = 3) +
  geom_segment(aes(x = ID,
                   xend = ID,
                   y = total_bill,
                   yend = mean(total_bill)
                   ),
               size = 1,
               color = "grey60") +
  geom_point(aes(x = ID, y = total_bill), 
             size = 7) +
  labs(title = "total_bill ~ 1",
       x = "",
       y = "",
       caption = "Relativ viel Residualstreuung")



p2 <- ggplot(tips2) +
  geom_hline(data = tips_sum,
             aes(yintercept = total_bill,
                 color = ordered(size)),
             size = 3) +
  geom_segment(aes(x = ID,
                   xend = ID,
                   y = total_bill,
                   yend = total_bill_mean_group),
               color = "grey80",
               size = 1) +
  geom_point(data = tips2,
             aes(x = ID, 
                 y = total_bill, 
                 color = ordered(size)),
             size = 7) +
  theme(legend.position = "none") +
  labs(title = "total_bill ~ size",
       x = "",
       y = "",
       caption = "Relativ wenig Residualstreuung") +
  scale_color_npg() +
  geom_label(data = tips_sum,
             aes(y = total_bill),
             x = 1, label = paste0("size: ", tips_sum$size), hjust = 0) 

grid.arrange(p1, p2, nrow = 1)
```




## Zusammenhang zwischen numerischen Variablen

### Streudiagramm

Visualisiert die gemeinsame Verteilung von zwei i.d.R. numerischen Variablen 
durch Punkte. 
Bei diskreten Merkmalen ggfs. verwackeln (engl.: jitter, `jitter()`).

:::{.footnotesize}
```{r out.width = "65%", fig.align="center", fig.asp=0.5, echo=FALSE}
plot1 <- gf_point(tip ~ total_bill, data = tips)   # zwei stetige Variablen
plot2 <- gf_point(tip ~ jitter(size), data = tips) # eine stetige, eine diskrete
grid.arrange(plot1, plot2, nrow = 1)
```
:::


### Kovariation

- **Kovarianz** beschreibt den linearen Zusammenhang zweier metrischer Merkmale: $s_{xy}=\frac{1}{n-1}\sum_{i=1}^n (x_i-\bar{x})(y_i-\bar{y})$: Die Werte beider Variablen einer Beobachtung werden mit dem jeweiligen Mittelwert der Variable verglichen. Vom Produkt der gemeinsamen Abweichungen wird $\approx$ Mittelwert berechnet.

- Der **Korrelationskoeffizient** nach Pearson^[Alternative: Spearman.] $r=\frac{s_{xy}}{sd_x \cdot sd_y}$ normiert die Kovarianz auf den Wertebereich $-1$ bis $+1$ durch Division der Kovarianz durch das Produkt der Standardabweichungen.^[Der Korrelationskoeffizient ist ein mathematischer Verwandter des Kosinus (zwischen den beiden Datenreihen aufgefasst als n-dimensionale Vektoren).]

- Korrelationskoeffizienten $r>0$ zeigen einen positiven linearen Zusammenhang an, $r<0$ einen negativen. Je größer $|r|$, desto größer ist der lineare Zusammenhang.

- **Achtung**: Korrelation heißt nicht zwangsläufig Kausalität, keine 
Korrelation heißt nicht zwangsläufig kein Zusammenhang oder keine Kausalität.^[Scheinkorrelation, siehe z.B. [http://www.tylervigen.com/spurious-correlations](http://www.tylervigen.com/spurious-correlations)]


### Kovarianz als mittleres Abweichungsrechteck

```{r rho-delta-rect, fig.asp = 0.8, echo = FALSE, out.width="80%"}
# Zeichengröße für die Rechteckflächen
cov.value.font.size <- 5
# Datentabelle auf die Tischgrößen 1 und 5 reduzieren. 
tips %>% filter(size == 1 | size == 5) -> df

# Mittelwerte berechnen und speichern
y.mean <- mean(~ tip, data = df)
x.mean <- mean(~ total_bill, data = df)

# Streudiagramm mit Covarianz-Anteilen zeichnen:
cov.value <- round(c((df$tip - y.mean) * (df$total_bill - x.mean)), 2)
cov.value.pos.x <- c((df$total_bill + x.mean)/2)
cov.value.pos.y <- c((df$tip + y.mean)/2)
# ist eh händisch programmiert (siehe bei rep), daher Positionen händisch geändert
cov.value.pos.y[2] <- cov.value.pos.y[2] - 0.07
cov.value.pos.y[7] <- cov.value.pos.y[7] + 0.07
cov.value.pos.y[1] <- cov.value.pos.y[1] - 0.2
cov.value.pos.x[1] <- cov.value.pos.x[1] - 0.4
cov.value.pos.y[3] <- cov.value.pos.y[3] - 0.2
cov.value.pos.x[3] <- cov.value.pos.x[3] + 0.4

gf_point(tip ~ total_bill, data = df) %>%
    gf_rect(tip + y.mean ~ total_bill + x.mean, 
            fill = c(rep("green", 6), "red", rep("green",2)), 
            color = c(rep("darkgreen", 6), "red", rep("darkgreen",2)), 
            alpha = 0.20) %>%
    gf_hline(yintercept = ~ y.mean, linetype = "dotted") %>%
    gf_vline(xintercept = ~ x.mean, linetype = "dotted") %>%
    gf_text(cov.value.pos.y ~ cov.value.pos.x, 
            size = cov.value.font.size, 
            color = c(rep("darkgreen", 6), "red", rep("darkgreen",2)), 
            label = cov.value)
```

```{r eval=FALSE, echo=FALSE}
tips %>% filter( size == 1 | size == 5) -> df
favstats(~ tip,  data = df) 
favstats(~ total_bill,  data = df)
cov.value
cov(tip ~ total_bill, data = df)
```


### Beispiele Kovariation

- Einkommen $x$ und Ausgaben $y$: positiver Zusammenhang: Personen mit überdurchschnittlichem Einkommen ($x_i-\bar{x}>0$) haben häufig auch überdurchschnittliche Ausgaben ($y_i-\bar{y}>0$), Personen mit unterdurchschnittlichem Einkommen ($x_i-\bar{x}<0$) haben häufig auch unterdurchschnittliche Ausgaben ($y_i-\bar{y}<0$). In beiden Fällen: $(x_i-\bar{x})\cdot(y_i-\bar{y})>0$.

- Preis $x$ und Absatz $y$: negativer Zusammenhang: Produkte mit überdurchschnittlichem Preis ($x_i-\bar{x}>0$) haben häufig einen unterdurchschnittlichen Absatz ($y_i-\bar{y}<0$), Produkte mit unterdurchschnittlichem Preis ($x_i-\bar{x}<0$) haben häufig einen überdurchschnittlichen Absatz ($y_i-\bar{y}>0$). In beiden Fällen: $(x_i-\bar{x})\cdot(y_i-\bar{y})<0$.


### Beispielrechnung Kovarianz und Korrelation
::: {.small}

| $i$ | $x_i$ | $y_i$ | $x_i-\bar{x}$ |  $y_i-\bar{y}$ | $(x_i-\bar{x})^2$ |  $(y_i-\bar{y})^2$ | $(x_i-\bar{x}) (y_i-\bar{y})$ |
|:---:|:---:|:---:|:-------:|:------:|:------:|:-------:|:--------------:|
|1|20|6|-4|-1|16|1|4|    
|2|24|7|0|0|0|0|0|
|3|30|10|6|3|36|9|18|   
|4|25|7|1|0|1|0|0|    
|5|21|5|-3|-2|9|4|6|    
|$\sum$|**120**|**35**|**0**|**0**|**62**|**14**|**28**|

:::

- Lagemaße: $\bar{x}=\frac{120}{5}=24; \bar{y}=\frac{35}{5}=7$
- Streuungsmaße: $\quad s_x^2=\frac{62}{4}=15{,}5; s_y^2=\frac{14}{4}=3{,}5; \quad s_x=\sqrt{15{,}5}=3{,}94; s_y=\sqrt{3{,}5}=1{,}87$
- Kovarianz: $s_{xy}=\frac{28}{4}=7$ 
- Korrelation^[Song: [https://www.causeweb.org](https://www.causeweb.org): [Monty Harper &copy; Correlation Does Not Imply Causation](https://www.causeweb.org/cause/resources/fun/songs/correlation-does-not-imply-causation)]: $r=\frac{7}{3{,}94 \cdot 1{,}87}=0{,}95$


### Korrelationskoeffizienten

```{r Visualisierung_Korrelation, fig.align="center", echo=FALSE, out.width="90%"}
#### Quelle http://moderndive.com/scripts/06-regression.R
## Leichte Anpassungen durch N. Markgraf
# library(mosaic)
library(mvtnorm) 
set.seed(2009)

correlation <- c(-0.999999, -0.90, -0.75, -0.30, 0.00, 0.30, 0.75, 0.90, 0.999999)
eps <- 0.00001
n_sim <- 100

values <- NULL
for (i in 1:length(correlation)) {
    rho <- correlation[i]
    rs <- rho * sqrt(50)
    sigma <- matrix(c(5, rs, rs, 10), 2, 2) 
    sim <- rmvnorm(
        n = n_sim,
        mean = c(20,40),
        sigma = sigma
    )
    r <- cor(sim[,1],sim[,2])
    new_err <- NULL
    new_r <- NULL
    err <- abs(rho - r)
    for (j in 1:1000) {
        sim_t <- rmvnorm(
            n = n_sim,
            mean = c(20,40),
            sigma = sigma
        )
        new_r <- cor(sim_t[,1], sim_t[,2])
        new_err <- abs(rho - new_r)
        if (new_err < err) {
            # cat(paste("want:",rho,"- got:",r,"- err:",err,"- new:",new_r,"new-err:",new_err,"\n"))
            sim <- sim_t
            r <- new_r
            err <- new_err
        }
        if (new_err < eps) {
            break
        }
    }
    sim %>%   
        as.data.frame() %>% 
        mutate(correlation = round(rho,2)) %>%
        mutate(reel_correlation = round(cor(V1,V2),2)) %>%
        mutate(reel_correlation_2 = round(r,2)) %>%
        mutate(cor_err = err) -> sim
    
    values <- bind_rows(values, sim)
}

ggplot(data = values, mapping = aes(V1, V2)) +
    geom_point() + 
    # stat_ellipse(level=0.999, type="norm", color="darkgreen", linetype="dotted", alpha=0.25) +
    # geom_lm(level=0.999) +
    facet_wrap(~ correlation, ncol = 3)  +
    labs(x = "", y = "") + 
    coord_fixed(ratio=25/40) + # (30-5)/(60-20)
    theme(
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()
    ) 
#unique(values$correlation)
#unique(values$reel_correlation)
#unique(values$reel_correlation_2)
#unique(values$cor_err)

detach("package:mvtnorm", unload=TRUE)
#detach("package:bindrcpp", unload=TRUE)
```


### Übung `r nextExercise()`: Nicht-lineare Zusammenhänge  {.exercise type=A-B-C-D answer=B}

```{r echo=FALSE, out.width = "40%", fig.align="center"}
set.seed(1896)
x <- seq(-2, 2, by = 0.1)
y <- x^2
gf_point(y ~ x)
rm(x)
rm(y)
```

Wie groß ist hier der Korrelationskoeffizient?

A.  $r \approx -1$
B.  $r \approx 0$
C.  $r \approx +1$
D.  $r$ kann nicht bestimmt werden.

::: {.notes} 
***B***: Der Korrelationskoeffizient misst nur lineare 
(d.h. insbesondere monotone) Zusammenhänge. 
Hier gilt $y=x^2$, trotzdem ist $r \approx 0$: 
Erst visualisieren, dann korrelieren.
:::


### Anscombe-Quartett

```{r, fig.align="center", echo=FALSE, out.width="80%"}
data(anscombe)
x <- c(anscombe$x1, anscombe$x2, anscombe$x3, anscombe$x4)
y <- c(anscombe$y1, anscombe$y2, anscombe$y3, anscombe$y4)
z <- factor(rep(1:4, each = 11))
ans <- data.frame(x = x, y = y, z = z)
gf_point(y ~ x | z, data = ans, main = "Anscombe Daten" )
```


### Anscombe-Daten: Erst visualisieren, dann korrelieren!

```{r, echo=FALSE}
real_sd <- function(x) {
#    sqrt(real_var(x))
    sd(x)
}

real_var <- function(x) {
    var(x)*(length(x) - 1)/length(x)
}

```

Die Verteilung von $x$ und $y$ unterscheidet sich sichtbar. 
Aber die deskriptiven Kennzahlen

- $\bar{x}\approx `r round(mean(x), 2)`; \bar{y}\approx`r round(mean(y), 2)`$ 
- $sd_x\approx `r round(real_sd(x), 2)`; sd_y\approx `r round(real_sd(y), 2)`$ 
- $r\approx `r round(cor(x,y), 2)`$ 

sind nahezu identisch -- in allen vier Fällen.^[Weiteres Beispiel z.B. unter [https://www.autodeskresearch.com/publications/samestats](https://www.autodeskresearch.com/publications/samestats)]


### Übung `r nextExercise()`: Korrelationskoeffizient {.exercise type=yesno answer=no}

Stimmt die Aussage: Der Korrelationskoeffizient ist robust gegen Ausreißer?

- Ja.
- Nein.

::: {.notes}

***Nein***, wie Sie auch an der Grafik erkennen können. 
Z.B. gibt es in der Grafik 4 des Anscombe-Quartett eigentlich gar keinen 
linearen Zusammenhang, dieser wird nur durch den einen Ausreißer vorgetäuscht. 
Die Kovarianz (auf der der Korrelationskoeffizient beruht) ist wie die Varianz 
empfindlich gegen Ausreißer.

Die robuste Alternative zum Korrelationskoeffizienten nach Bravais-Pearson ist 
der Rangkorrelationskoeffizient nach Spearman.

:::


### Zusammenhang Trinkgeld und Rechnungshöhe

Analysiere über Streudiagramm:

```{r xyplot, fig.align="center", out.width="60%"}
gf_point( tip # Variable auf y-Achse
        ~ total_bill, # Variable auf x-Achse
          data = tips) # Datentabelle
```


### Übung `r nextExercise()`: Zusammenhang Rechnungshöhe und Trinkgeld {.exercise type=A-B-C answer=C}

```{r xyplot, echo=FALSE, fig.align="right", out.width="20%"}
```

Welche Aussage stimmt?

A.  Es scheint keinen Zusammenhang zwischen Rechnungshöhe und Trinkgeld zu geben.
B.  Es scheint einen negativen Zusammenhang zwischen Rechnungshöhe und Trinkgeld zu geben.
C.  Es scheint einen positiven Zusammenhang zwischen Rechnungshöhe und Trinkgeld zu geben.

::: {.notes}
Die Punktewolke erstreckt sich von links unten nach rechts oben, d.h., 
im Mittel werden bei größeren Rechnungsbeträgen auch die Trinkgelder höher. 
Antwort ***C*** ist somit korrekt.
:::


### Korrelation Rechnungshöhe und Trinkgeld

Analysiere über Korrelationskoeffizienten nach Bravais-Pearson:^[Alternative: Rangkorrelation nach Spearman: `cor(tip ~ total_bill, data = tips, method = "spearman")`]

```{r cor,}
cor(tip ~ total_bill, # Variablen
     data = tips)  # Datentabelle
```

<!-- --->


### Zusammenhang Rechnungs- und relative Trinkgeldhöhe {include-only=deprecated}

Variable `rel_tip` erzeugen:

```{r}
tips <- tips %>% 
  mutate(rel_tip = tip/total_bill)
```


Streudiagramm:

```{r xyplot2, fig.align="center", out.width="35%"}
gf_point(rel_tip ~ total_bill, data = tips)
```

<!-- --->


### Zusammenhang Trinkgeld- und Rechnungshöhe gruppiert nach Geschlecht {.shrink include-only=deprecated}

Das Streudiagramm kann direkt gruppiert werden:

```{r out.width="60%", fig.align="center", fig.asp=0.5}
gf_point(tip ~ total_bill | sex, data = tips)
```


Die Korrelationskoeffizienten müssen gruppiert bestimmt werden:

```{r}
tips %>%
  group_by(sex) %>%
  summarise(cor(tip~total_bill, data=.))
```

<!-- --->


### Übung `r #nextExercise()`: Rechnungs- und relative Trinkgeldhöhe  {.exercise type=A-B-C-D answer=A include-only=deprecated}

```{r xyplot2, echo=FALSE, fig.align="right", out.width="20%"}
```

Welche Aussage stimmt ?

A.  Es gibt Ausreißer nach oben bei der relativen Trinkgeldhöhe.
B.  Es gibt Ausreißer nach unten bei der relativen Trinkgeldhöhe.
C.  Es gibt Ausreißer nach oben bei der Rechnungshöhe.
D.  Es gibt Ausreißer nach unten bei der Rechnungshöhe.

::: {.notes}
Es gibt Ausreißer nach oben bei der relativen Trinkgeldhöhe. 
Wie im dem Streudiagramm zu erkennen ist, gibt es einen (ca. 0.7) oder 
mehrere (ca. 0.7, 0.45, 0.35) Ausreißer, je nachdem, wo Sie die Grenze legen. 
Bei der Rechnungshöhe sind keine Ausreißer zu erkennen. 
Antwort ***A*** ist somit korrekt.
:::

<!-- -->


### Offene Übung `r nextExercise()`: Rechnungshöhe für Raucher bzw. Nichtraucher {.exercise type=essay}

Was können Sie über die Verteilung der Rechnungshöhe für Raucher bzw. 
Nichtraucher aussagen?^[Video: [https://www.causeweb.org](https://www.causeweb.org): [McLellan M &copy; Describe the Distribution](https://www.causeweb.org/cause/resources/library/r12611)] 


::: {.notes}

Mit folgenden Befehlen können Sie eine explorative Datenanalyse vornehmen:

`gf_histogram(~ total_bill | smoker, data = tips)`

`gf_boxplot(total_bill ~ smoker, data = tips)`

`favstats(total_bill ~ smoker, data = tips)`

`iqr(total_bill ~ smoker, data = tips)`

Beide Verteilungen sind rechtsschief (`gf_histogram`), bei den Nichtrauchern 
scheint es mehr Ausreißer zu geben (`gf_boxplot`). 
Im Mittel haben die Raucher eine etwas höhere Rechnungshöhe (`favstats`). 
Die Standardabweichung und der Interquartilsabstand (`iqr`) sind bei den 
Rauchern höher.

:::


### Offene Übung `r #nextExercise()`: Rechnungshöhe und Trinkgeld für Raucher bzw. Nichtraucher {.exercise type=essay include-only=deprecated}

Was können Sie über den Zusammenhang des Trinkgelds und der Rechnungshöhe für
Raucher bzw. Nichtraucher aussagen?

::: {.notes}
Mit folgenden Befehlen können Sie den (gruppierten) Zusammenhang untersuchen:

`gf_point(tip ~ total_bill | smoker, data = tips)`

`tips %>%  group_by(smoker) %>% summarise(cor(tip~total_bill))`

Der lineare Zusammenhang zwischen Trinkgeld und Rechnungshöhe ist bei den 
Nichtrauchern deutlich stärker ausgeprägt, was sowohl an den Grafiken zu sehen 
ist als auch am Korrelationskoeffizienten.
:::

<!-- -->

## Daten: Rückblick und Ausblick {exclude=MasterNeu}

### Tanjas Mindmap {exclude=MasterNeu}

```{r echo=FALSE, out.height = "85%", fig.align="center"}
knitr::include_graphics(file.path(pathToImages, "EDAwayto.jpg"), error = FALSE)
```


### Hypothesen und Datengenerierender Prozess {exclude=MasterNeu}

> Stelle Fragen zu den generierten Daten.

- Daten sind nicht nur *einfach da*, sie haben einen Entstehungsprozess.^[Daten-Ethik: diesen immer hinterfragen!]

- Häufig sind wir daran interessiert, eine Aussage über ihre Entstehung zu treffen.

- Eine solche Aussage geht über die unmittelbar vorliegenden Daten hinaus.


### Sarah {exclude=MasterNeu}

Sind Schimpansen in der Lage, Probleme zu lösen?^[[Premack, D., & Woodruff, G. (1978). Does the chimpanzee have a theory of mind?. Behavioral and brain sciences, 1(4), 515-526.](https://doi.org/10.1017/S0140525X00076512)]


:::::: {.columns}
::: {.column width="70%"}

[Der Versuch:]{.cstrong}  Sarah wurden Videos gezeigt, in denen Menschen vor (unlösbare) Probleme gestellt wurden.

Ein Video zeigte z.B. einen Menschen, der nicht aus einem abgeschlossenen Käfig herauskam. Sarah wurden nun zwei Karten mit Bildern zur Auswahl gestellt, auf einem dieser Bilder war die Problemlösung abgebildet. Nachdem sie die Videosequenz gesehen hatte, wurde sie gebeten, eines auszusuchen.

:::
::: {.column width="30%"}

```{r echo=FALSE, out.width = "95%", fig.align="center", cache=FALSE}
# Lizenzworkaround: 
extern_image_include("http://www.chimphaven.org/wp-content/uploads/2016/08/Sarah-4.jpg", "Sarah-4.jpg", pathToImages)
```

[Sarah (Anne) (* August 1959 – $\dagger$ 29. Juli 2019) im August 2016]{.tiny}
:::
::::::

Sarah wurden 8 Videos mit unterschiedlichen Problemen gezeigt.

Sarah lag bei allen 8 Problemen richtig!

Was bedeutet dieses Ergebnis? Wie erklären Sie dieses Ergebnis?


### Zwei Möglichkeiten {exclude=MasterNeu}

:::::: {.columns}
::: {.column width="48%"}

[1. Möglichkeit:]{.cstrong} **Sarah hat geraten,** 
es war reines Glück, dass sie in 8 von 8 Problemen richtig lag.

:::
::: {.column width="48%"}

[2. Möglichkeit:]{.cstrong} **Sarah kann Probleme abschätzen** 
und hat eine Fähigkeit, zu kombinieren und Probleme zu lösen.

:::
::::::


$\quad$


Was meinen Sie? Warum? Wie können Sie überzeugend argumentieren?


### Offene Übung `r nextExercise()`: Was wäre wenn ... {exclude=MasterNeu}

- Wenn das erste Modell für die Datengenerierung (*Zufall*) stimmen würde, können wir gemäß dieses Modells durch Münzwurf Daten *simulieren*.

- Dann können wir einschätzen, ob die beobachteten Daten (8 von 8 richtig) mit dem Modell *Raten* (Trefferanteil $\pi=0.5$) kompatibel sind.

Werfen Sie $8\times$ eine Münze und notieren Sie die Anzahl, in der die Münze *Kopf* zeigt. Zeichen Sie einen Dotplot Ihres Kursergebnisses.


::: {.notes}

*Individuell*. `Daten = Modell + Rest`: 
auch wenn wir alle das gleiche Modell hatten, so haben wir doch (zufällig) 
andere Daten gehabt. 

Auf lange Sicht wird das Ergebnis in etwa wie folgt aussehen:

```{r, echo=FALSE, fig.align="center", out.width="40%"}
gf_dist("binom", size = 8, prob = 0.5) %>%
  gf_labs(x = "Anzahl Kopf", y = "Relative Häufigkeit")
```

:::

### Übung `r nextExercise()`: Vergleich Daten und Modell {exclude=MasterNeu}


Sind die Daten (8 von 8 richtig) gut durch das Modell (*Raten*, $\pi=0.5$) erklärbar?^[Wenn Sie mehr Daten simulieren wollen: [https://fomshinyapps.shinyapps.io/Muenze/](https://fomshinyapps.shinyapps.io/Muenze/)]

- Ja.
- Nein.

::: {.notes}
***Nein***, *theoretisch* liegt die Wahrscheinlichkeit, zufällig 
8 von 8 richtig zu haben, wenn man zwischen zwei Alternativen rät, 
bei $0.5^8=`r round(dbinom(8,8, prob=0.5),4)`$.

Im Modell sind manche Daten wahrscheinlicher als andere.
:::

### Simulation mit R {exclude=MasterNeu}

```
- Bändige den Zufall; setze den Zufallszahlengenerator
- Die Datentabelle Sarah_Raet soll sein:
- Wiederhole 1000 mal: Wirf 8 mal eine (faire) Münze
- Gib den Anteil von 8 mal Kopf aus
```

```{r}
set.seed(1896)
Sarah_Raet <- do(1000) * rflip(n = 8)
prop( ~ heads, success = 8, data = Sarah_Raet)
```




## Zusammenfassung

### Tanjas Mindmap {include-only=MasterNeu}

```{r echo=FALSE, out.height = "85%", fig.align="center"}
knitr::include_graphics(file.path(pathToImages, "EDAwayto.jpg"), error = FALSE)
```


### Visualisierung (Tipps)

- Vermittle viele Zahlen, sonst brauchst du keine Grafik.

- Vermeide Ablenkung von der Hauptbotschaft.

- Fördere visuellen Vergleich.

- Unterschiedliche Farben nur, wenn es den Vergleich unterstützt.

- Vermeide 3D.

- Achte auf die Achsenskalierung.

**Verfahrensübersicht**: [https://www.data-to-viz.com/](https://www.data-to-viz.com/)

<!-- -->

### Cartoon: Visualisierung {exclude=qmwinf,eufom}

```{r echo=FALSE, out.width = "40%", fig.align="center", cache=FALSE}
# Lizenzworkaround: 
extern_image_include("https://www.causeweb.org/cause/sites/default/files/caption_contest/2016/Caption-Contest_08-2016.jpg", "cartoon0816.jpg", pathToImages)
```
"Ich weiß, dass Datenvisualisierung ein heißes Thema ist, aber gehst Du hier nicht ein wenig zu weit?"^[[https://www.CAUSEweb.org/](https://www.causeweb.org/cause/caption-contest/august/2016/results) &copy; J.B. Landers, Bildunterschrift B. Osyk]

<!-- -->


### Grafische Verfahren der Datenanalyse

- *Säulendiagramm / Balkendiagramm*: Häufigkeit von Merkmalsausprägungen (nominal, ordinal, metrisch diskret) -- `gf_bar()`.

- *Histogramm*: Häufigkeit von gruppierten Merkmalsausprägungen (metrisch) -- `gf_histogram()`.

- *Boxplot*: Visualisierung von Median, oberem und unterem Quartil, Minimum und Maximum, Ausreißern (metrisch) -- `gf_boxplot()`.

- *Violinplot*: Visualisierung der Dichtefunktion (und ggf. des Mittelwertes) der Verteilung (metrisch) -- `gf_violin()`.

- *Streudiagramm/ Scatterplot*: Darstellung der Merkmalsausprägungen von zwei i.d.R. metrischen Merkmalen^[bei kategorialen oder metrisch diskreten Merkmalen ggfs. *verwackeln*: `jitter()`] als Punkte -- `gf_point()`.

- *Mosaikplot*: Darstellung der Merkmalsausprägungen zweier nominaler Merkmale -- `mosaicplot()`.

- *Liniendiagramm*: Verlauf der Merkmalsausprägung eines Merkmals -- `gf_line()`.


### Übersicht deskriptive Kennzahlen

- `favstats()`: Zusammenfassung Kennzahlen numerischer Variablen.

- Einzeln, z.B. mit:
  - `mean()`: Mittelwert (metrisch),
  - `median()`: Median (ordinal, metrisch),
  - `iqr()`: Interquartilsabstand ((ordinal), metrisch),
  - `sd()`: Standardabweichung (metrisch).
  
- `cor()`: Korrelationskoeffizient (zwei metrische Merkmale. Für ordinale Merkmale: Rangkorrelation `method = "spearman"`).

- `prop()`: Anteile (nominal, ordinal, metrisch diskret -- relative Häufigkeiten einer Ausprägung).

- `tally()`: (Kreuz-)tabellierung (nominal, ordinal, metrisch diskret -- absolute oder relative Häufigkeiten aller Ausprägungen).


```{r finish-Einfuehrung-EDA, include=FALSE}
rm("nor", "schiefe", "bimod", "multimod", "gleich", "dat", "gh2", 
     "Sarah_Raet", "x", "y", "st", "gh10", "gh25", "gh50", "plot1", "plot2", 
     "xn", "xl", "xr", "xmm", "co2", "x1", "x2", "x3", "xg", 
     "hls", "hrs", "hsym")
rm(pathToImages)
finalizePart()
```
