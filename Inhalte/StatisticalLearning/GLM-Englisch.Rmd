
```{r setup-GLM, include=FALSE}
# ---------------------------------------------------------------------------
#% maintainer:
#%   - Norman Markgraf
#%
# ---------------------------------------------------------------------------
source("../../prelude.R")
initPart(
    "GLM",  # Dateiname ohne Suffix
    "StatisticalLearning"      # Verzeichnisname im Bilderverzeichnis 
    )
pathToImages = getPathToImages()
# ---------------------------------------------------------------------------


options(tinytex.verbose = TRUE)

```





```{r libs-GLM, include = FALSE}
library(mosaic)
library(gridExtra)
library(tidyverse)
library(ISLR)
library(brms)
library(broom)
data(tips, package = "reshape2")
```








# The generalized linear model (GLM)





## Basics



### Wouldn't it be great if ...


:::::: {.columns}
::: {.column width="60%"}

... we could enjoy the luxuries of the regression models to non-typical research questions as well?


\vspace{2cm}


[You can have this cake and it eat]{.cemph} 

Cf. [Post](https://lindeloev.github.io/tests-as-linear/) by Jonas Kristoffer Lindeløv

- Difference of means for $n>2$ groups
- Impact of study time on probability of getting an $A$
- What's the expected time for the next earthquake to occur? 
...



:::
::: {.column width="40%"}

```{r echo = FALSE, out.width="100%"}
knitr::include_graphics(file.path(pathToImages, "3f20qm.jpg"))
```

:::{.tiny}
Source: [imgflip](https://imgflip.com/i/3f20qm); [Lizenzhinweise](https://imgflip.com/terms)
:::



:::
::::::


### Typical statistical models are special cases of the linear model

The [general linear model]{.cemph} encompasses $t$-, $F-$Test etc. as special cases.



```{r echo = FALSE, out.width="90%"}
knitr::include_graphics(file.path(pathToImages, "linear_tests_cheat_sheet.pdf"))
```




### One model to rule ... a lot of them: The general linear model



Statistical models are typically specified like this:



$$
\begin{aligned}
y_i &\sim \text{N}(\mu_i, \sigma)\\
\mu_i &= \alpha + \beta x_i,
\end{aligned}
$$

where $N$ denotes the Normal distribution with expected value $\mu$ and standard variation $\sigma$.

Models of this type are called *general linear models*. They can be used if

- the dependent variable ($Y$) is modelled as a linear combination of the predictors
- there are no restrictions of allowed values of $Y$
- the errors/residuals ($y|\hat{y}$) are normally distributed
- you like models that can be interpreted with ease
- the right predictors have been selected




### Illustration with simulated data


*Example*: Assume that *exam score* $Y$ is a linear function of *study time* $X$, where $\beta = 0.7$ and some noise (error;  $\sigma$) exists, because the correlation is not perfect.



::::::{.columns}
:::{.column width="50%"}

```{r echo = TRUE, out.width="50%", eval = FALSE}
alpha <- 1; beta <- 0.7; sigma <- 1

x <- seq(-3, 3, by = 0.1) %>% 
  rep(100)
mu <- alpha + beta * x
y <- rnorm(n = length(x), 
           mean = mu, sd = sigma)

gf_point(y ~ x) %>% gf_lm()
```

:::
:::{.column width="40%"}


```{r echo = TRUE, out.width="100%", echo = FALSE, fig.asp = 1}
alpha <- 1; beta <- 0.7; sigma <- 1

x <- seq(-3, 3, by = 0.1) %>% 
  rep(100)
mu <- alpha + beta * x
y <- rnorm(n = length(x), 
           mean = mu, sd = sigma)

gf_jitter(y ~ x, alpha = .5) %>% gf_lm()
```

cf. `gf_bin2d(y ~ x)`
:::
::::::




### Hey linear regression, we're in trouble

Modelling eg., *counts*, we are bound to see trouble using the standard linear model:

  - Counts can only be positive, but the standard (general) linear model does not refrain from predicting negative values, which is a mess.
  - Count distributions do frequently apply range restrictions (eg., there are only 10 coins in the urn), but the standard model does not respect those restrictions.



```{r include = FALSE}
tips <- tips %>%
  mutate(sex_binary = case_when(
         sex == "Female" ~ 0,
         sex == "Male" ~ 1))

lm1 <- lm(sex_binary ~ total_bill, data = tips)
tips <- tips %>%
  mutate(sex_pred = predict(lm1))

tips %>%
  gf_point(sex_binary ~ total_bill, data = ., alpha = 0.3) %>% 
  gf_lm(color = "red") %>%
  gf_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE)
  #gf_lims(x = c(0, 100))  
  
```

  
  
  
```{r echo = FALSE, out.width= "100%", fig.asp=.3}
default <- as_tibble(ISLR::Default)
default <- default %>% 
  mutate(default_binary = ifelse(default == "Yes", 1, 0))


set.seed(123)
sample <- sample(c(TRUE, FALSE), nrow(default), replace = T, prob = c(0.6,0.4))
train <- default[sample, ]
test <- default[!sample, ]

model1 <- glm(default_binary ~ balance, family = "binomial", data = train)
model0 <- lm(default_binary ~ balance, data = train)


p1 <- train %>% 
  gf_point(default_binary ~ balance, data = train, alpha = .1) %>% 
  gf_lm() %>% 
  gf_labs(x = "", y = "", title = "Standard Linear Model")

p2 <- train %>% 
  gf_point(default_binary ~ balance, data = train, alpha = .1) %>%
  gf_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE) %>% 
  gf_labs(x = "", y = "", title = "Logistic Linear Model")


grid.arrange(p1, p2, nrow = 1)
```





### Generalizing the standard linear model

Let's generalize the standard linear model so that it fits for different purposes/distributions of $Y$ by

- choosing a distribution $p(y|\hat{y})$
- choosing a link function to "bend" the linear graph of the standard model

A model that predicts counts (eg., passed 4 of 5 exams) using a predictor $X$ could be defined in this way:


$$
\begin{aligned}
y_i &\sim \text{Bin}(n_i, p_i)\\
\text{logit}(p_i)& = \alpha + \beta x_i,
\end{aligned}
$$


where *Bin* denotes the Binomial distribution.





### Solving for $p_i$ (Inverse-Logit)


$\text{log}(\frac{p}{1-p})$ is called *Logit*.

$$
\begin{aligned}
\text{log}(\frac{p_i}{1-p_i}) &= \alpha + \beta x_i\\
\frac{p_i}{1-p_i} &= e^{ \alpha + \beta x_i}\\
p_i &= (1-p) e^{ \alpha + \beta x_i}\\
p_i &= e^{ \alpha + \beta x_i} - p_i e^{ \alpha + \beta x_i}\\
p_i +  p_i e^{ \alpha + \beta x_i} &=  e^{ \alpha + \beta x_i}\\
p_i(1 + e^{ \alpha + \beta x_i}) &=  e^{ \alpha + \beta x_i}\\
p_i &= \frac{e^{ \alpha + \beta x_i}}{1+ e^{ \alpha + \beta x_i}}
\end{aligned}
$$

$p_i$ denotes the probability in a Bernoulli experiment (eg., solving an item in an exam).




### Intuition for the Logit link


:::::: {.columns}
::: {.column width="50%"}

```{r eval = TRUE, results = "hold"}
x <- seq(-5, 5, by = .1)
y <- x
gf_line(y ~ x) %>% 
  gf_labs(y = "logits")
```

:::
:::{.column width="50%"}
```{r echo = TRUE, results = "hold"}
e <- 2.718
p <- e^x / (1 + e^x)
gf_line(p ~ x) %>% 
  gf_labs(y = "probability")
```

:::
::::::

## Frequent GLM variants

### Frequent GLM variants: Binomial distribution




:::::: {.columns}
::: {.column width="50%"}
- The Binomial distribution models the probability of getting $k$ successes in $n$ trials, where the probability of success is $p$. 

- All trials are assumed independent and identically distributed (constant probability for each trial). 

- Probaility mass function:

$$
f(k;n;p) = \binom {n}{k}p^{k}q^{n-k}
$$


:::
::: {.column width="50%"}

```{r echo = FALSE}
x <- seq(0,10)
y <- dbinom(x = x, size = 10, prob = .5)

gf_point(y ~ x)  %>% 
  gf_labs(title = "p = 50%") %>% 
  gf_refine(scale_x_continuous(breaks = 0:10))
```


:::
:::::: 

### Frequent GLM variants: Poisson distribution


:::::: {.columns}
::: {.column width="50%"}

- Similar to the Binomial distribtion, the Poission distribution is used for modelling counts.

- In contrast to the Binomial distribution, no upper bound of events (successes) is assumed.

- There's one parameter $\lambda$ denoting the expected rate (of events) per time period.

- Probability mass function for $k$ events:


$$
f(k;\lambda )={\frac {\lambda ^{k}e^{-\lambda }}{k!}}
$$



:::
::: {.column width="50%"}


```{r echo = FALSE}
x <- seq(0,10)
y <- dpois(x = x, lambda = 2)
d <- data.frame(x,y)

gf_point(y ~ x, data = d)  %>% 
  gf_labs(title = "Lambda = 2", y = "p") %>% 
  gf_refine(scale_x_continuous(breaks = 0:10))
```

- Link function: *Log link*: $log(\theta) = \alpha + \beta x_i$.
- Distribution family: *Poisson*
 


:::
::::::


### Frequent GLM variants: Exponential distribution

:::::: {.columns}
::: {.column width="50%"}

- The exponential distribution is frequently used for modelling of waiting times; what's the probability $p$ that it takes $x$ time units before an event occurs? 
- It has one parameter  $\lambda$, describing the average waiting time until the next event. Higher values denote *smaller* waiting times.
- Link function: *Log link*: $log(\theta) = \alpha + \beta x_i$.
- Distribution family: *Exponential*

- Probability density function:


$$
f(x;\lambda) = \begin{cases}
\lambda e^{-\lambda x} & x \ge 0, \\
0 & x < 0.
\end{cases}
$$



:::
::: {.column width="50%"}

```{r echo = FALSE}
x <- seq(0,10, by = .5)
y <- dexp(x = x, rate = 1/2)

gf_point(y ~ x) %>% gf_line() %>% 
  gf_labs(title = "Lambda = 1/2", y = "p")  %>% 
  gf_refine(scale_x_continuous(breaks = 0:10))
```

It can also be used to model exponential growth.



:::
:::::: 



### Frequent GLM variants: Normal distribution

:::::: {.columns}
::: {.column width="50%"}

- The Gaussian (Normal) is a member of this family.
- The Normal distribution reflects well a process that summarizes many independent and small influences.
- Like other members of the (Exponential) family, the Normal distribution maximizes entropy.
- Probability density function:

$$
f(x\mid \mu ,\sigma ^{2})={\frac {1}{\sqrt {2\pi \sigma ^{2}}}}e^{-{\frac {(x-\mu )^{2}}{2\sigma ^{2}}}}
$$

:::
::: {.column width="50%"}

```{r echo = FALSE}
x <- seq(-3,3, by = .1)
y <- dnorm(x = x, mean = 0, sd = 1)

gf_point(y ~ x) %>% gf_line() %>% 
  gf_labs(title = "Normal distribution", y = "d")  %>% 
  gf_refine(scale_x_continuous(breaks = -3:3))
```

:::
:::::: 



## GLM in R 

### GLM in R -- frequentist

- GLM workhorse: `glm()`.
- Specify the Link function and the distribution family using the `glm()` function.
- Maximum Likelihood is used for parameter estimation.
- Nice: Syntax of `glm()` is similar to `lm()`.


```{r eval = FALSE}
glm(y ~ x, data = data, 
    family = poisson(link = "log"))  # Poisson
lm(log(y) ~ x data = data)  # Exponential

data(tips, package = "reshape2")  # load some data
glm1 <- glm(sex ~ total_bill, data = tips, 
    family = binomial(link = "logit"))  # Binomial Regression
tidy(glm1)
```



### GLM in R -- The Bayesian way


R package `brms`^[no clue how to pronounce] can be used for modelling. 



```{r results = "hide", cache = TRUE}
library(brms)  # don't forget to install once
tips$sex_num <- ifelse(tips$sex == "Female", 0, 1)
model1 <- brm(data = tips,
              sex_num ~ total_bill,  
              family = bernoulli(), 
              file = "model1")  
```

:::{.small}
```{r}
tidy(model1)  # results/output
```
:::




## Case study


### Research question

Assume some epidemic advances; during the time period $t_2 - t_1$ an increases in cases $y$ are reported. How many cases are to be expected at time $t_x$?


:::::: {.columns}
::: {.column width="50%"}

:::{.tiny}
```{r out.height = "30%", fig.asp = 1/2}
# Intercept and slope:
alpha <- 1; beta <- 0.7

# noise sd:
sigma <- 3

# 5 measurement für 51 times:
t <- seq(0, 5, by = 0.1) %>% rep(5)  

# mean for each t:
mu <- exp(alpha + beta * t)  

# noise vector:
n <- rnorm(n = length(t),
                mean = 0, sd = sigma)

# observed: true + noise
y <- mu + n

# only positive values allowed
y <- ifelse(y < 0, y = -y, y)  
```
:::


:::
::: {.column width="40%"}


```{r out.width="100%"}
gf_point(y ~ t) %>% 
  gf_lm()
```



:::
::::::


The linear model does not fit well the data.


### Modelling using the Exponential distribution


::::::{.columns}
:::{.column width="40%"}

We have defined:

$$
\begin{aligned}
\text{log}(y_i) = \alpha + \beta t_i\\
y_i = e^{\alpha + \beta t_i}
\end{aligned}
$$

```{r out.width="80%"}
log_y <- log(y)
gf_point(log_y ~ t) %>% 
  gf_lm()
```
:::
:::{.column width="60%"}

Thus, a linear function can be used to model the *logged* $y_i$ values (`log_y`), via `lm()` or via `glm()`.

```{r}
lm1 <- lm(log_y ~ t)
coef(lm1)

glm1 <- glm(y ~ t, 
            family = gaussian(link = "log"))
coef(glm1)
```

:::
::::::


### Predict some values

How many cases are to expected at time 3.14?


```{r}
predict(glm1, newdata = data.frame(t=3.14), type = "response")
```

```{r}
pred1 <- predict(lm1, newdata = data.frame(t=3.14))
exp(pred1)
```


### Regression diagnostics via `plot(lm1)`

The diagnostics do not look to bad:

```{r out.width="70%", echo = FALSE}
par(mfrow = c(2, 2))
plot(lm1)
par(mfrow = c(1, 1))
```

